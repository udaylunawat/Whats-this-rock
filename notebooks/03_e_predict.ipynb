{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ca18a-7e2c-4ce3-9f10-858502ae23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04d4fe-ff69-43a5-8224-3e45bff6acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import wandb\n",
    "from hydra import compose, initialize\n",
    "from tensorflow.keras import models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca947c15-8726-4bff-8ca4-b5d75429a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_run_data():\n",
    "    \"\"\"Get data for a wandb sweep.\"\"\"\n",
    "    api = wandb.Api()\n",
    "    entity = \"rock-classifiers\"\n",
    "    project = \"Whats-this-rockv7\"\n",
    "    sweep_id = \"snemzvnp\"\n",
    "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "    runs = sorted(sweep.runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)\n",
    "\n",
    "    model_found = False\n",
    "    for run in runs:\n",
    "        ext_list = list(map(lambda x: x.name.split(\".\")[-1], list(run.files())))\n",
    "        if \"png\" and \"h5\" in ext_list:\n",
    "            val_acc = run.summary.get(\"val_accuracy\")\n",
    "            print(f\"Best run {run.name} with {val_acc}% validation accuracy\")\n",
    "            for f in run.files():\n",
    "                file_name = os.path.basename(f.name)\n",
    "                # print(os.path.basename(f.name))\n",
    "                if file_name.endswith(\"png\") and file_name.startswith(\"Classification\"):\n",
    "                    # Downloading Classification Report\n",
    "                    run.file(file_name).download(replace=True)\n",
    "                    print(\"Classification report donwloaded!\")\n",
    "\n",
    "            # Downloading model\n",
    "            run.file(\"model.h5\").download(replace=True)\n",
    "            print(\"Best model saved to model-best.h5\")\n",
    "            model_found = True\n",
    "            break\n",
    "\n",
    "    if not model_found:\n",
    "        print(\"No model found in wandb sweep, downloading fallback model!\")\n",
    "        os.system(\"wget -O model.h5 https://www.dropbox.com/s/urflwaj6fllr13d/model-best-efficientnet-val-acc-0.74.h5\")\n",
    "\n",
    "\n",
    "def preprocess_image(file, image_size):\n",
    "    \"\"\"Decode and resize image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : _type_\n",
    "        _description_\n",
    "    image_size : _type_\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    f = BytesIO(file.download_as_bytearray())\n",
    "    file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    file_name = \"model.h5\"\n",
    "    model = models.load_model(file_name)\n",
    "    optimizer = optimizers.Adam()\n",
    "    f1_score = tfa.metrics.F1Score(num_classes=num_classes, average=\"macro\", threshold=0.5)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\", f1_score],\n",
    "    )\n",
    "\n",
    "    print(\"Model loaded!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_prediction(file):\n",
    "    \"\"\"Get prediction for image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : File\n",
    "        Image file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Prediction with class name and confidence %.\n",
    "    \"\"\"\n",
    "    model = load_model()\n",
    "    img = preprocess_image(file, image_size=(cfg.image_size, cfg.image_size))\n",
    "    prediction = model.predict(np.array([img / 255]), batch_size=1)\n",
    "    assert prediction > 0\n",
    "    return (\n",
    "        f\"In this image I see {class_names[np.argmax(prediction)]} (with {(max(prediction[0]))*100:.3f}% confidence!)\"\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    # normalization_layer = layers.Rescaling(1.0 / 255)\n",
    "    initialize(config_path=\"../configs/\", version_base=\"1.2\")\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    batch_size = cfg.batch_size\n",
    "\n",
    "    class_names = [\n",
    "        \"Basalt\",\n",
    "        \"Coal\",\n",
    "        \"Granite\",\n",
    "        \"Limestone\",\n",
    "        \"Marble\",\n",
    "        \"Quartzite\",\n",
    "        \"Sandstone\",\n",
    "    ]\n",
    "    num_classes = len(class_names)\n",
    "    get_run_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636be19-4dd4-47cd-b8b4-30d5a908b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5198d2-1b53-45ac-bb13-9950252ab46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
