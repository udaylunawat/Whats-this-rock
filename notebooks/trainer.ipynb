{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4XOyKwTj_tD"
      },
      "source": [
        "# Todo\n",
        "\n",
        "- setting Freeze as False might also be making a difference\n",
        "- setting Train shuffle to True in ImageDataGenerator made all the difference\n",
        "    - Seems like it either because of the data or the preprocess step (augmentation), because the results have improved quite a lot with the inceptionv3 notebook data\n",
        "    - it can be also because of the way that guy handled the lr, if nothing above works out\n",
        "- InceptionV3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUSuNjlQZSi-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPdvkBCdKrVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ef9caf-1d22-43a6-c738-067d5af4d375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WandB API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['WANDB_MODE'] = 'online' # offline\n",
        "\n",
        "if 'WANDB_API_KEY' not in os.environ:\n",
        "  from getpass import getpass\n",
        "  secret = getpass('Enter WandB API Key: ')\n",
        "  os.environ['WANDB_API_KEY'] = secret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5aBLI9fKnta",
        "outputId": "6a71a26d-6d20-4bd5-a2e3-5aa730980bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=e38a174de241b98f8ef7aadcc3981466ae3aeb88c2ecb940ea59cf9af5f4b997\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb, tensorflow-addons, split-folders\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 split-folders-0.5.1 tensorflow-addons-0.17.1 wandb-0.13.2\n",
            "Downloading rock-classification.zip to data/0_raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2022-08-30 13:36:29--  https://www.dropbox.com/s/ltp4ly8ilvxlgas/kaggle.json\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/ltp4ly8ilvxlgas/kaggle.json [following]\n",
            "--2022-08-30 13:36:29--  https://www.dropbox.com/s/raw/ltp4ly8ilvxlgas/kaggle.json\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com/cd/0/inline/Br_AoBfPme6NVbxRSYbd2kJ0q4MsRQnLzx5sHEFRJLSLyvw0Wa1FRAWcgZSZzw6kratL0Cx81X-jj5X_dBmZIcSRSk2QdTVTDaB0g0jYSXI93eGXP6ShSP1hV7VTAr9vYZb_06CV8NKtCfIPGT7_mvH8ym9LQqlWrOhMm6tB79navg/file# [following]\n",
            "--2022-08-30 13:36:30--  https://uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com/cd/0/inline/Br_AoBfPme6NVbxRSYbd2kJ0q4MsRQnLzx5sHEFRJLSLyvw0Wa1FRAWcgZSZzw6kratL0Cx81X-jj5X_dBmZIcSRSk2QdTVTDaB0g0jYSXI93eGXP6ShSP1hV7VTAr9vYZb_06CV8NKtCfIPGT7_mvH8ym9LQqlWrOhMm6tB79navg/file\n",
            "Resolving uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com (uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com (uc6955c459ecb44e5713a5880914.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67 [text/plain]\n",
            "Saving to: ‘kaggle.json’\n",
            "\n",
            "     0K                                                       100% 11.6M=0s\n",
            "\n",
            "2022-08-30 13:36:30 (11.6 MB/s) - ‘kaggle.json’ saved [67/67]\n",
            "\n",
            "\r  0%|          | 0.00/159M [00:00<?, ?B/s]\r  3%|▎         | 5.00M/159M [00:00<00:18, 8.65MB/s]\r  6%|▌         | 9.00M/159M [00:00<00:13, 11.4MB/s]\r 21%|██        | 33.0M/159M [00:01<00:03, 37.7MB/s]\r 26%|██▌       | 41.0M/159M [00:01<00:04, 28.7MB/s]\r 36%|███▌      | 57.0M/159M [00:01<00:02, 40.5MB/s]\r 46%|████▌     | 73.0M/159M [00:03<00:04, 20.5MB/s]\r 66%|██████▌   | 105M/159M [00:03<00:01, 30.1MB/s] \r 71%|███████   | 113M/159M [00:05<00:02, 18.5MB/s]\r 82%|████████▏ | 130M/159M [00:05<00:01, 26.1MB/s]\r 91%|█████████ | 145M/159M [00:06<00:00, 26.7MB/s]\r 96%|█████████▌| 153M/159M [00:06<00:00, 30.2MB/s]\r100%|██████████| 159M/159M [00:06<00:00, 27.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "#!/bin/bash\n",
        "\n",
        "# setting up kaggle\n",
        "wget https://www.dropbox.com/s/ltp4ly8ilvxlgas/kaggle.json\n",
        "mkdir -p ~/.kaggle\n",
        "mv kaggle.json ~/.kaggle\n",
        "chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "pip install scikit-learn opencv-python kaggle pandas numpy tensorflow tensorflow-addons wandb split-folders\n",
        "\n",
        "# setting up data dir\n",
        "rm -rf data/1_extracted data/2_processed data/3_consume data/4_tfds_dataset data/corrupted_images\n",
        "mkdir -p data/0_raw data/1_extracted data/2_processed data/3_consume data/4_tfds_dataset data/corrupted_images checkpoints\n",
        "\n",
        "# # dataset 1 processing\n",
        "# kaggle datasets download salmaneunus/rock-classification --path data/0_raw/\n",
        "# unzip -q data/0_raw/rock-classification.zip -d data/1_extracted/\n",
        "# mv data/1_extracted/Dataset/Igneous/* data/2_processed\n",
        "# mv data/1_extracted/Dataset/Metamorphic/* data/2_processed\n",
        "# mv data/1_extracted/Dataset/Sedimentary/* data/2_processed\n",
        "\n",
        "# # dataset 2 processing\n",
        "# kaggle datasets download mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals --path data/0_raw/\n",
        "# unzip -q data/0_raw/igneous-metamorphic-sedimentary-rocks-and-minerals.zip -d data/1_extracted/\n",
        "# # https://serverfault.com/a/267266/979238\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/igneous\\ rocks/Basalt/* data/2_processed/Basalt/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/igneous\\ rocks/granite/* data/2_processed/Granite/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/metamorphic\\ rocks/marble/* data/2_processed/Marble/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/metamorphic\\ rocks/quartzite/* data/2_processed/Quartzite/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/sedimentary\\ rocks/coal/* data/2_processed/Coal/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/sedimentary\\ rocks/Limestone/* data/2_processed/Limestone/\n",
        "# mv --backup=t data/1_extracted/Rock_Dataset/sedimentary\\ rocks/Sandstone/* data/2_processed/Sandstone/\n",
        "# rm -rf data/1_extracted/Rock_Dataset/minerals\n",
        "\n",
        "# dataset 3 processing\n",
        "wget --quiet -O data/0_raw/dataset3.zip https://github.com/SmartPracticeschool/llSPS-INT-3797-Rock-identification-using-deep-convolution-neural-network/raw/master/dataset.zip\n",
        "unzip -q data/0_raw/dataset3.zip -d data/1_extracted/\n",
        "mv --backup=t data/1_extracted/dataset/*/Basalt/* data/2_processed/Basalt/\n",
        "mv --backup=t data/1_extracted/dataset/*/Granite/* data/2_processed/Granite/\n",
        "mv --backup=t data/1_extracted/dataset/*/Marble/* data/2_processed/Marble/\n",
        "mv --backup=t data/1_extracted/dataset/*/Quartzite/* data/2_processed/Quartzite/\n",
        "mv --backup=t data/1_extracted/dataset/*/Limestone/* data/2_processed/Limestone/\n",
        "mv --backup=t data/1_extracted/dataset/*/Sandstone/* data/2_processed/Sandstone/\n",
        "\n",
        "# # dataset 4 processing\n",
        "# kaggle datasets download neelgajare/rocks-dataset --path data/0_raw/\n",
        "# unzip -q data/0_raw/rocks-dataset.zip -d data/1_extracted/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Basalt/* data/2_processed/Basalt/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Granite/* data/2_processed/Granite/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Marble/* data/2_processed/Marble/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Quartzite/* data/2_processed/Quartzite/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Coal/* data/2_processed/Coal/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Limestone/* data/2_processed/Limestone/\n",
        "# cp -r --backup=t data/1_extracted/Rocks/Sandstone/* data/2_processed/Sandstone/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99xVwbxuQz9f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "default = dict(\n",
        "    notes='''\n",
        "    \n",
        "    Datasets used:[1], sampling: None, class-weights:True, \n",
        "    preprocessing:rescale=1./255,\n",
        "    \n",
        "    ''',\n",
        "    model_name=\"efficientnet\",\n",
        "    dataset=[3],\n",
        "    augment=True,\n",
        "    freeze=False,\n",
        "    finetune=True,\n",
        "    pretrained_model_link=\"rock-classifiers/Whats-this-rockv2/cvzc7hq0\",\n",
        "    sampling=None, # oversample, undersample, None\n",
        "    optimizer=\"adam\",\n",
        "    lr=.0007,\n",
        "    batch_size=32,\n",
        "    max_epochs=50,\n",
        "    image_size=224,\n",
        "    loss_fn='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "    earlystopping_patience=10,\n",
        "    earlystopping_min_delta = 0.02,\n",
        "    lr_reduce_patience=3,\n",
        "    lr_reduce_factor=.3,\n",
        "    threshold=.7,\n",
        ")\n",
        "\n",
        "# save dictionary to config.json file\n",
        "with open('config.json', 'w') as f:\n",
        "    json.dump(default, f)\n",
        "\n",
        "config = default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wim5iLIPGHaV",
        "outputId": "261d2256-44f9-4a5e-b779-188d42140813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2083 entries, 0 to 2082\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  2083 non-null   object\n",
            " 1   class      2083 non-null   object\n",
            " 2   file_path  2083 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 48.9+ KB\n",
            "None\n",
            "Quartzite    477\n",
            "Marble       387\n",
            "Coal         369\n",
            "Limestone    338\n",
            "Sandstone    325\n",
            "Granite      101\n",
            "Basalt        86\n",
            "Name: class, dtype: int64\n",
            "Splitting files in Train, Validation and Test and saving to data/4_tfds_dataset/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2083 files [00:00, 4903.97 files/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import argparse\n",
        "# https://stackoverflow.com/a/64006242/9292995\n",
        "import splitfolders\n",
        "\n",
        "\n",
        "def get_df(root=\"data/2_processed\"):\n",
        "    \"\"\"\n",
        "    root: a folder present inside data dir, which contains classes containing images\n",
        "    \"\"\"\n",
        "    classes = os.listdir(root)\n",
        "\n",
        "    class_names = []\n",
        "    images_paths = []\n",
        "    file_names = []\n",
        "\n",
        "    for class_name in classes:\n",
        "        for dirname, _, filenames in os.walk(os.path.join(root, class_name)):\n",
        "            for file_name in filenames:\n",
        "                images_paths.append(os.path.join(root, class_name, file_name))\n",
        "                class_names.append(class_name)\n",
        "                file_names.append(file_name)\n",
        "\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(list(zip(file_names, class_names, images_paths)), columns=['file_name', 'class', 'file_path'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "root = 'data/1_extracted/'\n",
        "print(get_df().info())\n",
        "print(get_df()['class'].value_counts())\n",
        "print(\"Splitting files in Train, Validation and Test and saving to data/4_tfds_dataset/\")\n",
        "if cfg.dataset.sampling == 'oversample':\n",
        "    # If your datasets is balanced (each class has the same number of samples), choose ratio otherwise fixed.\n",
        "    print(\"Finding smallest class for oversampling fixed parameter.\")\n",
        "    scc = min(get_df()['class'].value_counts())\n",
        "    print(f\"Smallest class count is {scc}\\n\")\n",
        "    splitfolders.fixed('data/2_processed', output=\"data/4_tfds_dataset\", oversample=True, fixed=((scc//2, scc//2)),\n",
        "                    seed=42)\n",
        "elif cfg.dataset.sampling == 'undersample':\n",
        "    splitfolders.fixed('data/2_processed', output=\"data/4_tfds_dataset\",\n",
        "                    fixed=(int(config['undersample']  * 0.75), int(config['undersample'] * 0.125), int(config['undersample']  * 0.125)),\n",
        "                    oversample=False,\n",
        "                    seed=42)\n",
        "else:\n",
        "    splitfolders.ratio('data/2_processed', output=\"data/4_tfds_dataset\",\n",
        "                    ratio=(0.75, 0.125, 0.125),\n",
        "                    seed=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw3LEjm3YHKh"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw_TGB1jK5db"
      },
      "outputs": [],
      "source": [
        "#@title Boilerplate Code { display-mode: \"form\" }\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "from tensorflow import image, cast, one_hot, float32\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "def get_generators(config):\n",
        "    if config['augment']:\n",
        "        print(\"Augmentation is True! rescale=1./255\")\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            horizontal_flip=True,\n",
        "            vertical_flip=True,\n",
        "            rotation_range=20,\n",
        "            rescale=1./255)  # preprocessing_function=scalar\n",
        "    elif not config['augment']:\n",
        "        print(\"No Augmentation!\")\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    else:\n",
        "        print(\"Error in config.augment. Stop Training!\")\n",
        "\n",
        "    train_dataset = train_datagen.flow_from_directory(\n",
        "        'data/4_tfds_dataset/train',\n",
        "        target_size=(config['image_size'], config['image_size']),\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255) # preprocessing_function=scalar\n",
        "    val_dataset = test_datagen.flow_from_directory(\n",
        "        'data/4_tfds_dataset/val',\n",
        "        shuffle=False,\n",
        "        color_mode='rgb',\n",
        "        target_size=(config['image_size'], config['image_size']),\n",
        "        batch_size=config['image_size'],\n",
        "        class_mode='categorical')\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        'data/4_tfds_dataset/test',\n",
        "        batch_size=config['batch_size'],\n",
        "        seed=42,\n",
        "        color_mode='rgb',\n",
        "        shuffle=False,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(\n",
        "            config['image_size'],\n",
        "            config['image_size']))\n",
        "\n",
        "    return train_dataset, val_dataset, test_generator\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow import image\n",
        "\n",
        "def get_optimizer(config):\n",
        "    if config['optimizer'] == 'adam':\n",
        "        opt = optimizers.Adam(learning_rate=config[\"lr\"])\n",
        "    elif config['optimizer'] == 'rms':\n",
        "        opt = optimizers.RMSprop(learning_rate=config[\"lr\"],\n",
        "                                 rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "    elif config['optimizer'] == 'sgd':\n",
        "        opt = optimizers.SGD(learning_rate=config[\"lr\"])\n",
        "    elif config['optimizer'] == 'adamax':\n",
        "        opt = optimizers.Adamax(learning_rate=config[\"lr\"])\n",
        "\n",
        "    return opt\n",
        "\n",
        "\n",
        "def get_model(config):\n",
        "    models_dict = {\n",
        "        'efficientnet': get_efficientnet,\n",
        "        'resnet': get_resnet,\n",
        "        'mobilenet': get_mobilenet,\n",
        "        'mobilenetv2': get_mobilenetv2,\n",
        "        'inceptionresnetv2': get_inceptionresnetv2,\n",
        "        'efficientnetv2m': get_efficientnetv2m,\n",
        "    }\n",
        "\n",
        "    return models_dict[config['model_name']](config)\n",
        "\n",
        "\n",
        "def get_best_checkpoint():\n",
        "    max = 0\n",
        "    best_model = None\n",
        "    for file_name in os.listdir('checkpoints'):\n",
        "        if file_name.endswith('5'):\n",
        "            val_acc = int(os.path.basename(file_name).split('.')[-2])\n",
        "            if val_acc > max:\n",
        "                max = val_acc\n",
        "                best_model = file_name\n",
        "    return best_model\n",
        "\n",
        "\n",
        "def get_model_weights(train_generator):\n",
        "    class_weights = class_weight.compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(train_generator.classes),\n",
        "        y=train_generator.classes)\n",
        "\n",
        "    train_class_weights = dict(enumerate(class_weights))\n",
        "    return train_class_weights\n",
        "\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization, LeakyReLU, Input\n",
        "from tensorflow.keras import regularizers, initializers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "\n",
        "def get_mobilenet(config):\n",
        "    model = Sequential()\n",
        "    base_model = applications.MobileNet(weights='imagenet', include_top=False, input_shape=(config['image_size'], config['image_size'], 3))\n",
        "    base_model.trainable = not config['freeze']\n",
        "    model.add(base_model)\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(256, activation='relu',\n",
        "                    kernel_regularizer=regularizers.l1_l2(0.01),\n",
        "                    bias_regularizer=regularizers.l1_l2(0.01)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Dense(config['num_classes'], activation='softmax'))\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_mobilenetv2(config):\n",
        "    base_model = applications.MobileNetV2(\n",
        "        input_shape=(\n",
        "            config['image_size'],\n",
        "            config['image_size'],\n",
        "            3),\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False)\n",
        "\n",
        "    # freeze layers\n",
        "    base_model.trainable = not config['freeze']\n",
        "\n",
        "    # Add untrained final layers\n",
        "    model = Sequential(\n",
        "        [\n",
        "            base_model,\n",
        "            GlobalAveragePooling2D(),\n",
        "            Dense(1024),\n",
        "            Dropout(0.3),\n",
        "            Dense(256),\n",
        "            Dropout(0.3),\n",
        "            Dense(64),\n",
        "            Dropout(0.3),\n",
        "            Dense(config['num_classes'], activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_efficientnet(config):\n",
        "    \"\"\"Construct a simple categorical CNN following the Keras tutorial.\"\"\"\n",
        "    base_model = applications.EfficientNetV2B0(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(config['image_size'], config['image_size'], 3),\n",
        "        classifier_activation=\"softmax\",\n",
        "        include_preprocessing=False,\n",
        "    )\n",
        "\n",
        "    # freeze layers\n",
        "    base_model.trainable = not config['freeze']\n",
        "    # Add untrained final layers\n",
        "    model = Sequential(\n",
        "        [\n",
        "            base_model,\n",
        "            GlobalAveragePooling2D(),\n",
        "            Dense(1024),\n",
        "            Dropout(0.3),\n",
        "            Dense(256),\n",
        "            Dropout(0.3),\n",
        "            Dense(64),\n",
        "            Dropout(0.3),\n",
        "            Dense(config['num_classes'], activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_resnet(config):\n",
        "    base_model = applications.ResNet50(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_tensor=(\n",
        "            config['image_size'],\n",
        "            config['image_size'],\n",
        "            3)\n",
        "    )\n",
        "    base_model.trainable = not config['freeze']\n",
        "\n",
        "    model = Sequential(\n",
        "        [\n",
        "            base_model,\n",
        "            Flatten(),\n",
        "            BatchNormalization(),\n",
        "            Dense(256, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            BatchNormalization(),\n",
        "            Dense(128, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            BatchNormalization(),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            BatchNormalization(),\n",
        "            Dense(config[\"num_classes\"], activation='softmax'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_efficientnetv2m(config):\n",
        "    inputs = Input(shape=(config['image_size'], config['image_size'], 3))\n",
        "    model = applications.EfficientNetV2M(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = not config['freeze']\n",
        "\n",
        "    # Rebuild top\n",
        "    x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = Dense(config['num_classes'], activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = Model(inputs, outputs, name=\"EfficientNet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_inceptionresnetv2(config):\n",
        "    base_model = applications.InceptionResNetV2(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(config[\"image_size\"], config[\"image_size\"], 3),\n",
        "        pooling='max')\n",
        "\n",
        "    base_model.trainable = not config['freeze']\n",
        "\n",
        "    model = Sequential(\n",
        "        [\n",
        "            base_model,\n",
        "            BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
        "            Dense(256, kernel_regularizer=regularizers.l2(l=0.016),\n",
        "                  activity_regularizer=regularizers.l1(0.006),\n",
        "                  bias_regularizer=regularizers.l1(0.006),\n",
        "                  activation='relu',\n",
        "                  kernel_initializer=initializers.GlorotUniform(seed=123)),\n",
        "            Dropout(rate=.45, seed=123),\n",
        "            Dense(config[\"num_classes\"],\n",
        "                  activation='softmax',\n",
        "                  kernel_initializer=initializers.GlorotUniform(seed=123)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(labels, y, _y):\n",
        "\n",
        "    l = [ 0 for _ in range(len(labels))]\n",
        "    z = [ [0 for _ in range(len(labels))] for _ in range(len(labels))]\n",
        "    h = [ [0 for _ in range(len(labels))] for _ in range(len(labels)) ]\n",
        "\n",
        "    for i, j in zip(y, _y):\n",
        "        z[j][i] += 1\n",
        "        l[i] += 1\n",
        "\n",
        "    x = labels.copy()\n",
        "    y = labels.copy()\n",
        "\n",
        "    z_labels = [ [ str(col) if col != 0 else '' for col in row ] for row in z]\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(len(labels)):\n",
        "            if i == j:\n",
        "                h[i][j] = 'Correctly predicted ' + str(z[i][j]) + ' out of ' + str(l[i]) + ' ' + labels[i] + ' with accuracy ' + str(z[i][j] / l[i])\n",
        "            else:\n",
        "                if z[j][i] == 0:\n",
        "                    h[j][i] = ''\n",
        "                else:\n",
        "                    h[j][i] = 'Incorrectly predicted ' + str(z[j][i]) + ' out of ' + str(l[i]) + ' ' + labels[i] + ' as ' + labels[j]\n",
        "\n",
        "    fig = ff.create_annotated_heatmap(z, x = x, y = y, text = h, annotation_text = z_labels, hoverinfo = 'text', colorscale ='Blues')\n",
        "\n",
        "    fig.update_layout(width = 850, height = 550)\n",
        "    fig.update_layout(margin = dict(t = 100, l = 200))\n",
        "\n",
        "    fig.add_annotation(dict(font=dict(color=\"#094973\",size=16), x = 0.5, y = -0.10, showarrow = False, text=\"True Class\", xref=\"paper\", yref=\"paper\"))\n",
        "    fig.add_annotation(dict(font=dict(color=\"#094973\",size=16), x = -0.17, y = 0.5, showarrow = False, text=\"Predicted Class\", textangle=-90, xref=\"paper\", yref=\"paper\"))\n",
        "\n",
        "    fig.show()\n",
        "    return fig\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# from src.data.utils import get_generators\n",
        "# from model.utils import get_model, get_optimizer, get_best_checkpoint, get_model_weights, LRA\n",
        "# import plot\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# *IMPORANT*: Have to do this line *before* importing tensorflow\n",
        "# os.environ['PYTHONHASHSEED'] = str(1)\n",
        "\n",
        "\n",
        "def reset_random_seeds():\n",
        "    os.environ['PYTHONHASHSEED'] = str(1)\n",
        "    set_seed(1)\n",
        "    np.random.seed(1)\n",
        "    random.seed(1)\n",
        "\n",
        "\n",
        "class custom_callback(Callback):\n",
        "    \"\"\"log lr and clear checkpoints.\"\"\"\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = float(K.get_value(self.model.optimizer.lr))  # get the current learning rate\n",
        "        wandb.log({'lr': lr}, commit=False)\n",
        "        max = 0\n",
        "        for file_name in os.listdir('checkpoints'):\n",
        "            val_acc = int(os.path.basename(file_name).split('.')[-2])\n",
        "            if val_acc > max:\n",
        "                max = val_acc\n",
        "            if val_acc < max:\n",
        "                os.remove(os.path.join('checkpoints', file_name))\n",
        "\n",
        "def print_in_color(\n",
        "    txt_msg, fore_tupple, back_tupple,\n",
        "):\n",
        "    # prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple\n",
        "    # text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
        "    rf, gf, bf = fore_tupple\n",
        "    rb, gb, bb = back_tupple\n",
        "    msg = \"{0}\" + txt_msg\n",
        "    mat = (\n",
        "        \"\\33[38;2;\"\n",
        "        + str(rf)\n",
        "        + \";\"\n",
        "        + str(gf)\n",
        "        + \";\"\n",
        "        + str(bf)\n",
        "        + \";48;2;\"\n",
        "        + str(rb)\n",
        "        + \";\"\n",
        "        + str(gb)\n",
        "        + \";\"\n",
        "        + str(bb)\n",
        "        + \"m\"\n",
        "    )\n",
        "    print(msg.format(mat), flush=True)\n",
        "    print(\"\\33[0m\", flush=True)  # returns default print color to back to black\n",
        "    return\n",
        "\n",
        "\n",
        "class LRA(Callback):\n",
        "    reset = False\n",
        "    count = 0\n",
        "    stop_count = 0\n",
        "    tepochs = 0\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        wandb,\n",
        "        model,\n",
        "        patience,\n",
        "        stop_patience,\n",
        "        threshold,\n",
        "        factor,\n",
        "        dwell,\n",
        "        model_name,\n",
        "        freeze,\n",
        "        initial_epoch,\n",
        "    ):\n",
        "        super(LRA, self).__init__()\n",
        "        self.model = model\n",
        "        self.wandb = wandb\n",
        "        self.patience = patience  # specifies how many epochs without improvement before learning rate is adjusted\n",
        "        self.stop_patience = stop_patience\n",
        "        self.threshold = threshold  # specifies training accuracy threshold when lr will be adjusted based on validation loss\n",
        "        self.factor = factor  # factor by which to reduce the learning rate\n",
        "        self.dwell = dwell\n",
        "        self.lr = float(\n",
        "            K.get_value(model.optimizer.lr)\n",
        "        )  # get the initiallearning rate and save it in self.lr\n",
        "        self.highest_tracc = 0.0  # set highest training accuracy to 0\n",
        "        self.lowest_vloss = np.inf  # set lowest validation loss to infinity\n",
        "        # self.count=0 # initialize counter that counts epochs with no improvement\n",
        "        # self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement\n",
        "        self.initial_epoch = initial_epoch\n",
        "        # self.epochs = epochs\n",
        "        best_weights = (\n",
        "            self.model.get_weights()\n",
        "        )  # set a class vaiable so weights can be loaded after training is completed\n",
        "        msg = \" \"\n",
        "        if freeze == True:\n",
        "            msgs = f\" Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback\"\n",
        "        else:\n",
        "            msgs = f\" Starting training using base model { model_name} training all layers \"\n",
        "        print_in_color(msgs, (244, 252, 3), (55, 65, 80))\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.now = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
        "        later = time.time()\n",
        "        duration = later - self.now\n",
        "        if epoch == self.initial_epoch or LRA.reset == True:\n",
        "            LRA.reset = False\n",
        "            msg = \"{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^11s}{8:^8s}\".format(\n",
        "                \"Epoch\",\n",
        "                \"Loss\",\n",
        "                \"Accuracy\",\n",
        "                \"V_loss\",\n",
        "                \"V_acc\",\n",
        "                \"LR\",\n",
        "                \"Next LR\",\n",
        "                \"Monitor\",\n",
        "                \"Duration\",\n",
        "            )\n",
        "            print_in_color(msg, (244, 252, 3), (55, 65, 80))\n",
        "\n",
        "        lr = float(\n",
        "            K.get_value(self.model.optimizer.lr)\n",
        "        )  # get the current learning rate\n",
        "        self.wandb.log({\"lr\": lr})\n",
        "        current_lr = lr\n",
        "        v_loss = logs.get(\"val_loss\")  # get the validation loss for this epoch\n",
        "        acc = logs.get(\"accuracy\")  # get training accuracy\n",
        "        v_acc = logs.get(\"val_accuracy\")\n",
        "        loss = logs.get(\"loss\")\n",
        "        color = (0, 255, 0)\n",
        "        # print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n",
        "        if (\n",
        "            acc < self.threshold\n",
        "        ):  # if training accuracy is below threshold adjust lr based on training accuracy\n",
        "            monitor = \"accuracy\"\n",
        "            if acc > self.highest_tracc:  # training accuracy improved in the epoch\n",
        "                self.highest_tracc = acc  # set new highest training accuracy\n",
        "                LRA.best_weights = (\n",
        "                    self.model.get_weights()\n",
        "                )  # traing accuracy improved so save the weights\n",
        "                self.count = 0  # set count to 0 since training accuracy improved\n",
        "                self.stop_count = 0  # set stop counter to 0\n",
        "                if v_loss < self.lowest_vloss:\n",
        "                    self.lowest_vloss = v_loss\n",
        "                color = (0, 255, 0)\n",
        "                self.lr = lr\n",
        "            else:\n",
        "                # training accuracy did not improve check if this has happened for patience number of epochs\n",
        "                # if so adjust learning rate\n",
        "                if self.count >= self.patience - 1:\n",
        "                    color = (255, 0, 0)\n",
        "                    self.lr = lr * self.factor  # adjust the learning by factor\n",
        "                    K.set_value(\n",
        "                        self.model.optimizer.lr, self.lr\n",
        "                    )  # set the learning rate in the optimizer\n",
        "                    self.count = 0  # reset the count to 0\n",
        "                    self.stop_count = self.stop_count + 1\n",
        "                    if self.dwell:\n",
        "                        self.model.set_weights(\n",
        "                            LRA.best_weights\n",
        "                        )  # return to better point in N space\n",
        "                    else:\n",
        "                        if v_loss < self.lowest_vloss:\n",
        "                            self.lowest_vloss = v_loss\n",
        "                else:\n",
        "                    self.count = self.count + 1  # increment patience counter\n",
        "        else:  # training accuracy is above threshold so adjust learning rate based on validation loss\n",
        "            monitor = \"val_loss\"\n",
        "            if v_loss < self.lowest_vloss:  # check if the validation loss improved\n",
        "                self.lowest_vloss = (\n",
        "                    v_loss  # replace lowest validation loss with new validation loss\n",
        "                )\n",
        "                LRA.best_weights = (\n",
        "                    self.model.get_weights()\n",
        "                )  # validation loss improved so save the weights\n",
        "                self.count = 0  # reset count since validation loss improved\n",
        "                self.stop_count = 0\n",
        "                color = (0, 255, 0)\n",
        "                self.lr = lr\n",
        "            else:  # validation loss did not improve\n",
        "                if self.count >= self.patience - 1:\n",
        "                    color = (255, 0, 0)\n",
        "                    self.lr = self.lr * self.factor  # adjust the learning rate\n",
        "                    self.stop_count = (\n",
        "                        self.stop_count + 1\n",
        "                    )  # increment stop counter because lr was adjusted\n",
        "                    self.count = 0  # reset counter\n",
        "                    K.set_value(\n",
        "                        self.model.optimizer.lr, self.lr\n",
        "                    )  # set the learning rate in the optimizer\n",
        "                    if self.dwell:\n",
        "                        self.model.set_weights(\n",
        "                            LRA.best_weights\n",
        "                        )  # return to better point in N space\n",
        "                else:\n",
        "                    self.count = self.count + 1  # increment the patience counter\n",
        "                if acc > self.highest_tracc:\n",
        "                    self.highest_tracc = acc\n",
        "        msg = f\"{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}\"\n",
        "        print_in_color(msg, color, (55, 65, 80))\n",
        "        if (\n",
        "            self.stop_count > self.stop_patience - 1\n",
        "        ):  # check if learning rate has been adjusted stop_count times with no improvement\n",
        "            msg = f\" training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement\"\n",
        "            print_in_color(msg, (0, 255, 0), (55, 65, 80))\n",
        "            self.model.stop_training = True  # stop training\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "    # model = load_model('checkpoints/visionary-sweep-10-efficientnet-epoch-2-val_f1_score-0.65.hdf5')\n",
        "\n",
        "    file_name = \"model-best.h5\"\n",
        "    if config['finetune']:\n",
        "        if not os.path.exists(file_name):\n",
        "            api = wandb.Api()\n",
        "            run = api.run(config['pretrained_model_link'])  # different-sweep-34-efficientnet-epoch-3-val_f1_score-0.71.hdf5\n",
        "            run.file(file_name).download()\n",
        "            print(f\"Downloaded pretrained model {config['pretrained_model_link']}, \\nfinetuning...\")\n",
        "        else:\n",
        "            print(\"model.h5 already present, \\nfinetuning...\")\n",
        "        model = load_model(file_name)\n",
        "    else:\n",
        "        # build model\n",
        "        K.clear_session()\n",
        "        model = get_model(config)\n",
        "\n",
        "    # print(model.summary())\n",
        "\n",
        "    print(f\"Model loaded: {model.name}\\n\\n\")\n",
        "    opt = get_optimizer(config)\n",
        "\n",
        "    config['metrics'].append(tfa.metrics.F1Score(\n",
        "        num_classes=config['num_classes'],\n",
        "        average='macro',\n",
        "        threshold=0.5))\n",
        "\n",
        "    class_weights = get_model_weights(train_dataset)\n",
        "\n",
        "    model.compile(loss=config['loss_fn'],\n",
        "                    optimizer=opt,\n",
        "                    metrics=config[\"metrics\"])\n",
        "    model_checkpoint = ModelCheckpoint(\"checkpoints/\"+f\"{wandb.run.name}-\" + config[\"model_name\"]+\n",
        "                                        \"-epoch-{epoch}-val_f1_score-{val_f1_score:.2f}.hdf5\", save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=config['lr_reduce_factor'], patience=config['lr_reduce_patience'], verbose=1, min_lr=0.000001)\n",
        "    earlystopper = EarlyStopping(\n",
        "        monitor='val_loss', patience=config['earlystopping_patience'], verbose=1, mode='auto', min_delta=config['earlystopping_min_delta'],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    # Define WandbCallback for experiment tracking\n",
        "    wandbcallback = WandbCallback(monitor=\"val_f1_score\",\n",
        "                                    save_model=(True),\n",
        "                                    save_graph=(False),\n",
        "                                    log_evaluation=True,\n",
        "                                    generator=val_dataset,\n",
        "                                    )\n",
        "    # callbacks = [wandbcallback, earlystopper, model_checkpoint, reduce_lr, custom_callback()]\n",
        "    callbacks = [LRA(wandb=wandb, model=model, patience=config['lr_reduce_patience'], stop_patience=config['earlystopping_patience'], threshold=.9,\n",
        "                        factor=config['lr_reduce_factor'], dwell=False, model_name=config['model_name'], freeze=config['freeze'], initial_epoch=0),\n",
        "                    model_checkpoint, wandbcallback, custom_callback()]\n",
        "    LRA.tepochs = config['max_epochs']  # used to determine value of last epoch for printing\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=config[\"max_epochs\"],\n",
        "        validation_data=val_dataset,\n",
        "        callbacks=callbacks,\n",
        "        class_weight=class_weights,\n",
        "        workers=-1,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate():\n",
        "    # Scores\n",
        "    scores = model.evaluate(test_dataset, return_dict=True)\n",
        "    print('Scores: ', scores)\n",
        "    wandb.log({'Test Accuracy': scores['accuracy']})\n",
        "    wandb.log({'Test F1 Score': scores['f1_score']})\n",
        "\n",
        "    # Predict\n",
        "    pred = model.predict(test_dataset, verbose=1)\n",
        "    predicted_class_indices = np.argmax(pred, axis=1)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = plot_confusion_matrix(labels, test_dataset.classes, predicted_class_indices)\n",
        "    wandb.log({\"Confusion Matrix\": cm})\n",
        "\n",
        "    # Classification Report\n",
        "    cl_report = classification_report(test_dataset.classes,\n",
        "                                      predicted_class_indices,\n",
        "                                      labels=[0, 1, 2, 3, 4, 5, 6],\n",
        "                                      target_names=labels,\n",
        "                                      output_dict=True)\n",
        "    print(cl_report)\n",
        "\n",
        "    cr = sns.heatmap(pd.DataFrame(cl_report).iloc[:-1, :].T, annot=True)\n",
        "    plt.savefig('imgs/cr.png')\n",
        "    wandb.log({\"Classification Report Image:\": wandb.Image('imgs/cr.png', caption=\"Classification Report\")})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3fdcda2249d84838b2bceb2d0dded322",
            "9e49e29749644dfba9bad3725104ec47",
            "302374ff7a6d4a739a1aebb9022185c7",
            "a24ab6df6e054fc2ae1c8b383cd2227b",
            "db34859ac4794ab3a3ed7130fd0a2114",
            "9e53f48761f44ebc97f91074dc64a598",
            "5a3e470e0a6548f4972f3759ffa93274",
            "6de29a88152a419cacf8f81ddd5c58bc"
          ]
        },
        "id": "6eM9stW_GEAY",
        "outputId": "c52490ae-5a4a-4c4a-bbd2-88055d5a5d3c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default config:- {\n",
            "  \"notes\": \"\\n    \\n    Datasets used:[1], sampling: None, class-weights:True, \\n    preprocessing:rescale=1./255,\\n    \\n    \",\n",
            "  \"model_name\": \"efficientnet\",\n",
            "  \"augment\": true,\n",
            "  \"freeze\": false,\n",
            "  \"finetune\": true,\n",
            "  \"pretrained_model_link\": \"rock-classifiers/Whats-this-rockv2/cvzc7hq0\",\n",
            "  \"sampling\": null,\n",
            "  \"optimizer\": \"adam\",\n",
            "  \"lr\": 0.0007,\n",
            "  \"batch_size\": 32,\n",
            "  \"max_epochs\": 50,\n",
            "  \"image_size\": 224,\n",
            "  \"loss_fn\": \"categorical_crossentropy\",\n",
            "  \"metrics\": [\n",
            "    \"accuracy\"\n",
            "  ],\n",
            "  \"earlystopping_patience\": 10,\n",
            "  \"earlystopping_min_delta\": 0.02,\n",
            "  \"lr_reduce_patience\": 3,\n",
            "  \"lr_reduce_factor\": 0.3,\n",
            "  \"threshold\": 0.7\n",
            "}\n",
            " P.S - Not used in sweeps.\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:1w27s6yb) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3fdcda2249d84838b2bceb2d0dded322",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='272.703 MB of 272.703 MB uploaded (0.827 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test F1 Score</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▅▄▆█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>f1_score</td><td>▁▅▄▅█</td></tr><tr><td>loss</td><td>█▄▅▃▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▁█▂█</td></tr><tr><td>val_f1_score</td><td>▂▁█▃▄</td></tr><tr><td>val_loss</td><td>▅█▂▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.72393</td></tr><tr><td>Test Accuracy</td><td>0.63774</td></tr><tr><td>Test F1 Score</td><td>0.58464</td></tr><tr><td>accuracy</td><td>0.69813</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_f1_score</td><td>0.47143</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>f1_score</td><td>0.68221</td></tr><tr><td>loss</td><td>0.93634</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>val_accuracy</td><td>0.64202</td></tr><tr><td>val_f1_score</td><td>0.54612</td></tr><tr><td>val_loss</td><td>1.11871</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hardy-voice-844</strong>: <a href=\"https://wandb.ai/rock-classifiers/Whats-this-rockv2/runs/1w27s6yb\" target=\"_blank\">https://wandb.ai/rock-classifiers/Whats-this-rockv2/runs/1w27s6yb</a><br/>Synced 5 W&B file(s), 1 media file(s), 10 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220830_142736-1w27s6yb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:1w27s6yb). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220830_150219-3narvdgp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/rock-classifiers/Whats-this-rockv2/runs/3narvdgp\" target=\"_blank\">treasured-paper-846</a></strong> to <a href=\"https://wandb.ai/rock-classifiers/Whats-this-rockv2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmentation is True! rescale=1./255\n",
            "Found 1547 images belonging to 7 classes.\n",
            "Found 257 images belonging to 7 classes.\n",
            "Found 265 images belonging to 7 classes.\n",
            "Downloaded Trained model, finetuning...\n",
            "Model loaded: sequential\n",
            "\n",
            "\n",
            "\u001b[38;2;244;252;3;48;2;55;65;80m Starting training using base model efficientnet training all layers \n",
            "\u001b[0m\n",
            "Epoch 1/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 1.3013 - accuracy: 0.6083 - f1_score: 0.5427\u001b[38;2;244;252;3;48;2;55;65;80m Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR   Monitor  Duration\n",
            "\u001b[0m\n",
            "\u001b[38;2;0;255;0;48;2;55;65;80m 1 /50     1.301   60.827   1.03177  65.370   0.00070  0.00070  accuracy   43.51  \n",
            "\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) efficientnetv2-b0_input with unsupported characters which will be renamed to efficientnetv2_b0_input in the SavedModel.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220830_150219-3narvdgp/files/model-best)... Done. 0.8s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49/49 [==============================] - 93s 2s/step - loss: 1.3013 - accuracy: 0.6083 - f1_score: 0.5427 - val_loss: 1.0318 - val_accuracy: 0.6537 - val_f1_score: 0.5873\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 1.1238 - accuracy: 0.6593 - f1_score: 0.6210\u001b[38;2;0;255;0;48;2;55;65;80m 2 /50     1.124   65.934   0.93636  64.981   0.00070  0.00070  accuracy   31.05  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 32s 650ms/step - loss: 1.1238 - accuracy: 0.6593 - f1_score: 0.6210 - val_loss: 0.9364 - val_accuracy: 0.6498 - val_f1_score: 0.6077\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.9573 - accuracy: 0.7188 - f1_score: 0.6773\u001b[38;2;0;255;0;48;2;55;65;80m 3 /50     0.957   71.881   1.24103  59.533   0.00070  0.00070  accuracy   30.81  \n",
            "\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) efficientnetv2-b0_input with unsupported characters which will be renamed to efficientnetv2_b0_input in the SavedModel.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220830_150219-3narvdgp/files/model-best)... Done. 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 86s 2s/step - loss: 0.9573 - accuracy: 0.7188 - f1_score: 0.6773 - val_loss: 1.2410 - val_accuracy: 0.5953 - val_f1_score: 0.5511\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.8245 - accuracy: 0.7149 - f1_score: 0.6885\u001b[38;2;0;255;0;48;2;55;65;80m 4 /50     0.825   71.493   0.97889  70.039   0.00070  0.00070  accuracy   31.01  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 631ms/step - loss: 0.8245 - accuracy: 0.7149 - f1_score: 0.6885 - val_loss: 0.9789 - val_accuracy: 0.7004 - val_f1_score: 0.6553\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.7789 - f1_score: 0.7597\u001b[38;2;0;255;0;48;2;55;65;80m 5 /50     0.690   77.893   1.12557  64.981   0.00070  0.00070  accuracy   31.36  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 635ms/step - loss: 0.6900 - accuracy: 0.7789 - f1_score: 0.7597 - val_loss: 1.1256 - val_accuracy: 0.6498 - val_f1_score: 0.6027\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6974 - accuracy: 0.7692 - f1_score: 0.7554\u001b[38;2;0;255;0;48;2;55;65;80m 6 /50     0.697   76.923   0.89084  69.650   0.00070  0.00070  accuracy   34.13  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 35s 723ms/step - loss: 0.6974 - accuracy: 0.7692 - f1_score: 0.7554 - val_loss: 0.8908 - val_accuracy: 0.6965 - val_f1_score: 0.6828\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.7938 - f1_score: 0.7684\u001b[38;2;0;255;0;48;2;55;65;80m 7 /50     0.677   79.379   1.13052  69.261   0.00070  0.00070  accuracy   32.47  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 33s 662ms/step - loss: 0.6773 - accuracy: 0.7938 - f1_score: 0.7684 - val_loss: 1.1305 - val_accuracy: 0.6926 - val_f1_score: 0.6762\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.7860 - f1_score: 0.7671\u001b[38;2;0;255;0;48;2;55;65;80m 8 /50     0.683   78.604   1.58920  61.868   0.00070  0.00070  accuracy   35.49  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 36s 722ms/step - loss: 0.6827 - accuracy: 0.7860 - f1_score: 0.7671 - val_loss: 1.5892 - val_accuracy: 0.6187 - val_f1_score: 0.5777\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.6139 - accuracy: 0.7809 - f1_score: 0.7618\u001b[38;2;0;255;0;48;2;55;65;80m 9 /50     0.614   78.087   1.34472  63.813   0.00070  0.00070  accuracy   30.48  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 621ms/step - loss: 0.6139 - accuracy: 0.7809 - f1_score: 0.7618 - val_loss: 1.3447 - val_accuracy: 0.6381 - val_f1_score: 0.6207\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5235 - accuracy: 0.8190 - f1_score: 0.8104\u001b[38;2;0;255;0;48;2;55;65;80m10 /50     0.524   81.900   1.42671  65.759   0.00070  0.00070  accuracy   30.58  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 625ms/step - loss: 0.5235 - accuracy: 0.8190 - f1_score: 0.8104 - val_loss: 1.4267 - val_accuracy: 0.6576 - val_f1_score: 0.6112\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.8332 - f1_score: 0.8155\u001b[38;2;0;255;0;48;2;55;65;80m11 /50     0.526   83.323   1.37492  67.704   0.00070  0.00070  accuracy   31.68  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 32s 648ms/step - loss: 0.5262 - accuracy: 0.8332 - f1_score: 0.8155 - val_loss: 1.3749 - val_accuracy: 0.6770 - val_f1_score: 0.6138\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8643 - f1_score: 0.8532\u001b[38;2;0;255;0;48;2;55;65;80m12 /50     0.376   86.425   1.53258  59.533   0.00070  0.00070  accuracy   30.32  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 621ms/step - loss: 0.3761 - accuracy: 0.8643 - f1_score: 0.8532 - val_loss: 1.5326 - val_accuracy: 0.5953 - val_f1_score: 0.5566\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8371 - f1_score: 0.8307\u001b[38;2;0;255;0;48;2;55;65;80m13 /50     0.480   83.710   1.57575  61.089   0.00070  0.00070  accuracy   30.67  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 625ms/step - loss: 0.4801 - accuracy: 0.8371 - f1_score: 0.8307 - val_loss: 1.5758 - val_accuracy: 0.6109 - val_f1_score: 0.5696\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.8584 - f1_score: 0.8572\u001b[38;2;0;255;0;48;2;55;65;80m14 /50     0.357   85.844   1.31158  65.759   0.00070  0.00070  accuracy   30.42  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 615ms/step - loss: 0.3570 - accuracy: 0.8584 - f1_score: 0.8572 - val_loss: 1.3116 - val_accuracy: 0.6576 - val_f1_score: 0.6026\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8804 - f1_score: 0.8716\u001b[38;2;0;255;0;48;2;55;65;80m15 /50     0.356   88.041   1.39708  67.315   0.00070  0.00070  accuracy   30.42  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 622ms/step - loss: 0.3558 - accuracy: 0.8804 - f1_score: 0.8716 - val_loss: 1.3971 - val_accuracy: 0.6732 - val_f1_score: 0.6297\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8565 - f1_score: 0.8458\u001b[38;2;0;255;0;48;2;55;65;80m16 /50     0.415   85.650   1.09028  68.093   0.00070  0.00070  accuracy   30.42  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 622ms/step - loss: 0.4153 - accuracy: 0.8565 - f1_score: 0.8458 - val_loss: 1.0903 - val_accuracy: 0.6809 - val_f1_score: 0.6303\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8701 - f1_score: 0.8681\u001b[38;2;0;255;0;48;2;55;65;80m17 /50     0.377   87.007   1.58171  64.202   0.00070  0.00070  accuracy   30.36  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 619ms/step - loss: 0.3774 - accuracy: 0.8701 - f1_score: 0.8681 - val_loss: 1.5817 - val_accuracy: 0.6420 - val_f1_score: 0.6065\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8817 - f1_score: 0.8791\u001b[38;2;0;255;0;48;2;55;65;80m18 /50     0.352   88.171   1.32840  62.646   0.00070  0.00070  accuracy   30.46  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 621ms/step - loss: 0.3518 - accuracy: 0.8817 - f1_score: 0.8791 - val_loss: 1.3284 - val_accuracy: 0.6265 - val_f1_score: 0.5949\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.8668 - f1_score: 0.8619\u001b[38;2;0;255;0;48;2;55;65;80m19 /50     0.436   86.684   1.39818  66.537   0.00070  0.00070  accuracy   30.56  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 623ms/step - loss: 0.4364 - accuracy: 0.8668 - f1_score: 0.8619 - val_loss: 1.3982 - val_accuracy: 0.6654 - val_f1_score: 0.6165\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.8268 - f1_score: 0.8119\u001b[38;2;0;255;0;48;2;55;65;80m20 /50     0.562   82.676   1.56698  63.813   0.00070  0.00070  accuracy   30.53  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 622ms/step - loss: 0.5624 - accuracy: 0.8268 - f1_score: 0.8119 - val_loss: 1.5670 - val_accuracy: 0.6381 - val_f1_score: 0.6163\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3799 - accuracy: 0.8759 - f1_score: 0.8624\u001b[38;2;255;0;0;48;2;55;65;80m21 /50     0.380   87.589   1.20314  70.817   0.00070  0.00021  accuracy   30.54  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 622ms/step - loss: 0.3799 - accuracy: 0.8759 - f1_score: 0.8624 - val_loss: 1.2031 - val_accuracy: 0.7082 - val_f1_score: 0.6517\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.9056 - f1_score: 0.8843\u001b[38;2;0;255;0;48;2;55;65;80m22 /50     0.359   90.562   1.16407  68.482   0.00021  0.00021  val_loss   30.43  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 622ms/step - loss: 0.3590 - accuracy: 0.9056 - f1_score: 0.8843 - val_loss: 1.1641 - val_accuracy: 0.6848 - val_f1_score: 0.6542\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9341 - f1_score: 0.9347\u001b[38;2;0;255;0;48;2;55;65;80m23 /50     0.161   93.407   1.13762  72.763   0.00021  0.00021  val_loss   30.53  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 613ms/step - loss: 0.1608 - accuracy: 0.9341 - f1_score: 0.9347 - val_loss: 1.1376 - val_accuracy: 0.7276 - val_f1_score: 0.6907\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9457 - f1_score: 0.9513\u001b[38;2;255;0;0;48;2;55;65;80m24 /50     0.125   94.570   1.43247  72.374   0.00021  0.00006  val_loss   32.14  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 32s 657ms/step - loss: 0.1251 - accuracy: 0.9457 - f1_score: 0.9513 - val_loss: 1.4325 - val_accuracy: 0.7237 - val_f1_score: 0.6842\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9509 - f1_score: 0.9560\u001b[38;2;0;255;0;48;2;55;65;80m25 /50     0.117   95.087   1.34591  71.595   0.00006  0.00006  val_loss   30.52  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 621ms/step - loss: 0.1168 - accuracy: 0.9509 - f1_score: 0.9560 - val_loss: 1.3459 - val_accuracy: 0.7160 - val_f1_score: 0.6847\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9593 - f1_score: 0.9577\u001b[38;2;0;255;0;48;2;55;65;80m26 /50     0.117   95.928   1.32365  71.984   0.00006  0.00006  val_loss   30.53  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 622ms/step - loss: 0.1166 - accuracy: 0.9593 - f1_score: 0.9577 - val_loss: 1.3237 - val_accuracy: 0.7198 - val_f1_score: 0.6865\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9599 - f1_score: 0.9624\u001b[38;2;255;0;0;48;2;55;65;80m27 /50     0.102   95.992   1.34098  71.984   0.00006  0.00002  val_loss   30.42  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 620ms/step - loss: 0.1025 - accuracy: 0.9599 - f1_score: 0.9624 - val_loss: 1.3410 - val_accuracy: 0.7198 - val_f1_score: 0.6840\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9535 - f1_score: 0.9585\u001b[38;2;0;255;0;48;2;55;65;80m28 /50     0.114   95.346   1.30406  71.206   0.00002  0.00002  val_loss   30.52  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 624ms/step - loss: 0.1137 - accuracy: 0.9535 - f1_score: 0.9585 - val_loss: 1.3041 - val_accuracy: 0.7121 - val_f1_score: 0.6809\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9716 - f1_score: 0.9739\u001b[38;2;0;255;0;48;2;55;65;80m29 /50     0.076   97.156   1.29297  71.206   0.00002  0.00002  val_loss   30.42  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 618ms/step - loss: 0.0762 - accuracy: 0.9716 - f1_score: 0.9739 - val_loss: 1.2930 - val_accuracy: 0.7121 - val_f1_score: 0.6712\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9683 - f1_score: 0.9665\u001b[38;2;255;0;0;48;2;55;65;80m30 /50     0.078   96.833   1.28762  70.817   0.00002  0.00001  val_loss   30.44  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 621ms/step - loss: 0.0780 - accuracy: 0.9683 - f1_score: 0.9665 - val_loss: 1.2876 - val_accuracy: 0.7082 - val_f1_score: 0.6733\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.9683 - f1_score: 0.9699\u001b[38;2;0;255;0;48;2;55;65;80m31 /50     0.083   96.833   1.27605  72.763   0.00001  0.00001  val_loss   30.35  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 620ms/step - loss: 0.0830 - accuracy: 0.9683 - f1_score: 0.9699 - val_loss: 1.2761 - val_accuracy: 0.7276 - val_f1_score: 0.7034\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9612 - f1_score: 0.9626\u001b[38;2;0;255;0;48;2;55;65;80m32 /50     0.085   96.122   1.30740  71.206   0.00001  0.00001  val_loss   30.41  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 621ms/step - loss: 0.0848 - accuracy: 0.9612 - f1_score: 0.9626 - val_loss: 1.3074 - val_accuracy: 0.7121 - val_f1_score: 0.6825\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9690 - f1_score: 0.9711\u001b[38;2;255;0;0;48;2;55;65;80m33 /50     0.080   96.897   1.29992  71.984   0.00001  0.00000  val_loss   30.53  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 623ms/step - loss: 0.0798 - accuracy: 0.9690 - f1_score: 0.9711 - val_loss: 1.2999 - val_accuracy: 0.7198 - val_f1_score: 0.6899\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9690 - f1_score: 0.9682\u001b[38;2;0;255;0;48;2;55;65;80m34 /50     0.082   96.897   1.26206  72.374   0.00000  0.00000  val_loss   30.48  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 623ms/step - loss: 0.0820 - accuracy: 0.9690 - f1_score: 0.9682 - val_loss: 1.2621 - val_accuracy: 0.7237 - val_f1_score: 0.6871\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9677 - f1_score: 0.9694\u001b[38;2;0;255;0;48;2;55;65;80m35 /50     0.080   96.768   1.27507  71.595   0.00000  0.00000  val_loss   30.64  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 624ms/step - loss: 0.0804 - accuracy: 0.9677 - f1_score: 0.9694 - val_loss: 1.2751 - val_accuracy: 0.7160 - val_f1_score: 0.6836\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9625 - f1_score: 0.9635\u001b[38;2;255;0;0;48;2;55;65;80m36 /50     0.086   96.251   1.30437  72.763   0.00000  0.00000  val_loss   30.44  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 620ms/step - loss: 0.0857 - accuracy: 0.9625 - f1_score: 0.9635 - val_loss: 1.3044 - val_accuracy: 0.7276 - val_f1_score: 0.6926\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9716 - f1_score: 0.9745\u001b[38;2;0;255;0;48;2;55;65;80m37 /50     0.076   97.156   1.33091  72.763   0.00000  0.00000  val_loss   30.56  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 625ms/step - loss: 0.0755 - accuracy: 0.9716 - f1_score: 0.9745 - val_loss: 1.3309 - val_accuracy: 0.7276 - val_f1_score: 0.6918\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9651 - f1_score: 0.9687\u001b[38;2;0;255;0;48;2;55;65;80m38 /50     0.093   96.509   1.31900  71.984   0.00000  0.00000  val_loss   30.37  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 620ms/step - loss: 0.0934 - accuracy: 0.9651 - f1_score: 0.9687 - val_loss: 1.3190 - val_accuracy: 0.7198 - val_f1_score: 0.6792\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9638 - f1_score: 0.9681\u001b[38;2;255;0;0;48;2;55;65;80m39 /50     0.087   96.380   1.30177  72.763   0.00000  0.00000  val_loss   30.44  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 617ms/step - loss: 0.0868 - accuracy: 0.9638 - f1_score: 0.9681 - val_loss: 1.3018 - val_accuracy: 0.7276 - val_f1_score: 0.6896\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9677 - f1_score: 0.9683\u001b[38;2;0;255;0;48;2;55;65;80m40 /50     0.083   96.768   1.29078  71.595   0.00000  0.00000  val_loss   30.34  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 615ms/step - loss: 0.0835 - accuracy: 0.9677 - f1_score: 0.9683 - val_loss: 1.2908 - val_accuracy: 0.7160 - val_f1_score: 0.6857\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9709 - f1_score: 0.9701\u001b[38;2;0;255;0;48;2;55;65;80m41 /50     0.081   97.091   1.29684  71.206   0.00000  0.00000  val_loss   30.28  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 616ms/step - loss: 0.0811 - accuracy: 0.9709 - f1_score: 0.9701 - val_loss: 1.2968 - val_accuracy: 0.7121 - val_f1_score: 0.6922\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9657 - f1_score: 0.9654\u001b[38;2;255;0;0;48;2;55;65;80m42 /50     0.086   96.574   1.31982  68.482   0.00000  0.00000  val_loss   30.39  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 620ms/step - loss: 0.0861 - accuracy: 0.9657 - f1_score: 0.9654 - val_loss: 1.3198 - val_accuracy: 0.6848 - val_f1_score: 0.6615\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9683 - f1_score: 0.9692\u001b[38;2;0;255;0;48;2;55;65;80m43 /50     0.075   96.833   1.34677  71.984   0.00000  0.00000  val_loss   30.34  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 619ms/step - loss: 0.0750 - accuracy: 0.9683 - f1_score: 0.9692 - val_loss: 1.3468 - val_accuracy: 0.7198 - val_f1_score: 0.6854\n",
            "Epoch 44/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9644 - f1_score: 0.9670\u001b[38;2;0;255;0;48;2;55;65;80m44 /50     0.096   96.445   1.32298  70.817   0.00000  0.00000  val_loss   30.56  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 31s 623ms/step - loss: 0.0958 - accuracy: 0.9644 - f1_score: 0.9670 - val_loss: 1.3230 - val_accuracy: 0.7082 - val_f1_score: 0.6747\n",
            "Epoch 45/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9670 - f1_score: 0.9659\u001b[38;2;255;0;0;48;2;55;65;80m45 /50     0.083   96.703   1.28806  70.817   0.00000  0.00000  val_loss   30.39  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 621ms/step - loss: 0.0826 - accuracy: 0.9670 - f1_score: 0.9659 - val_loss: 1.2881 - val_accuracy: 0.7082 - val_f1_score: 0.6735\n",
            "Epoch 46/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9632 - f1_score: 0.9659\u001b[38;2;0;255;0;48;2;55;65;80m46 /50     0.089   96.315   1.33339  71.984   0.00000  0.00000  val_loss   30.38  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 618ms/step - loss: 0.0892 - accuracy: 0.9632 - f1_score: 0.9659 - val_loss: 1.3334 - val_accuracy: 0.7198 - val_f1_score: 0.6819\n",
            "Epoch 47/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9696 - f1_score: 0.9683\u001b[38;2;0;255;0;48;2;55;65;80m47 /50     0.080   96.962   1.30136  72.374   0.00000  0.00000  val_loss   30.40  \n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 621ms/step - loss: 0.0795 - accuracy: 0.9696 - f1_score: 0.9683 - val_loss: 1.3014 - val_accuracy: 0.7237 - val_f1_score: 0.6853\n",
            "Epoch 48/50\n",
            "49/49 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9729 - f1_score: 0.9748\u001b[38;2;255;0;0;48;2;55;65;80m48 /50     0.065   97.285   1.27100  71.206   0.00000  0.00000  val_loss   30.28  \n",
            "\u001b[0m\n",
            "\u001b[38;2;0;255;0;48;2;55;65;80m training has been halted at epoch 48 after 10 adjustments of learning rate with no improvement\n",
            "\u001b[0m\n",
            "49/49 [==============================] - 30s 619ms/step - loss: 0.0648 - accuracy: 0.9729 - f1_score: 0.9748 - val_loss: 1.2710 - val_accuracy: 0.7121 - val_f1_score: 0.6865\n",
            "9/9 [==============================] - 2s 184ms/step - loss: 1.6670 - accuracy: 0.7170 - f1_score: 0.6963\n",
            "Scores:  {'loss': 1.6670373678207397, 'accuracy': 0.7169811129570007, 'f1_score': 0.6963229179382324}\n",
            "9/9 [==============================] - 3s 186ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"d86b616e-7a79-400c-91cf-ffd5819d4c9e\" class=\"plotly-graph-div\" style=\"height:550px; width:850px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d86b616e-7a79-400c-91cf-ffd5819d4c9e\")) {                    Plotly.newPlot(                        \"d86b616e-7a79-400c-91cf-ffd5819d4c9e\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"hoverinfo\":\"text\",\"reversescale\":false,\"showscale\":false,\"text\":[[\"Correctly predicted 5 out of 12 Basalt with accuracy 0.4166666666666667\",\"Incorrectly predicted 3 out of 47 Coal as Basalt\",\"Incorrectly predicted 1 out of 14 Granite as Basalt\",\"\",\"Incorrectly predicted 3 out of 48 Marble as Basalt\",\"\",\"\"],[\"\",\"Correctly predicted 39 out of 47 Coal with accuracy 0.8297872340425532\",\"\",\"\",\"Incorrectly predicted 2 out of 48 Marble as Coal\",\"Incorrectly predicted 1 out of 61 Quartzite as Coal\",\"\"],[\"\",\"\",\"Correctly predicted 10 out of 14 Granite with accuracy 0.7142857142857143\",\"Incorrectly predicted 2 out of 42 Limestone as Granite\",\"\",\"Incorrectly predicted 1 out of 61 Quartzite as Granite\",\"Incorrectly predicted 1 out of 41 Sandstone as Granite\"],[\"Incorrectly predicted 2 out of 12 Basalt as Limestone\",\"Incorrectly predicted 1 out of 47 Coal as Limestone\",\"Incorrectly predicted 2 out of 14 Granite as Limestone\",\"Correctly predicted 32 out of 42 Limestone with accuracy 0.7619047619047619\",\"Incorrectly predicted 5 out of 48 Marble as Limestone\",\"Incorrectly predicted 3 out of 61 Quartzite as Limestone\",\"Incorrectly predicted 2 out of 41 Sandstone as Limestone\"],[\"Incorrectly predicted 2 out of 12 Basalt as Marble\",\"Incorrectly predicted 1 out of 47 Coal as Marble\",\"\",\"Incorrectly predicted 4 out of 42 Limestone as Marble\",\"Correctly predicted 27 out of 48 Marble with accuracy 0.5625\",\"Incorrectly predicted 12 out of 61 Quartzite as Marble\",\"\"],[\"Incorrectly predicted 3 out of 12 Basalt as Quartzite\",\"Incorrectly predicted 1 out of 47 Coal as Quartzite\",\"\",\"\",\"Incorrectly predicted 7 out of 48 Marble as Quartzite\",\"Correctly predicted 39 out of 61 Quartzite with accuracy 0.639344262295082\",\"\"],[\"\",\"Incorrectly predicted 2 out of 47 Coal as Sandstone\",\"Incorrectly predicted 1 out of 14 Granite as Sandstone\",\"Incorrectly predicted 4 out of 42 Limestone as Sandstone\",\"Incorrectly predicted 4 out of 48 Marble as Sandstone\",\"Incorrectly predicted 5 out of 61 Quartzite as Sandstone\",\"Correctly predicted 38 out of 41 Sandstone with accuracy 0.926829268292683\"]],\"x\":[\"Basalt\",\"Coal\",\"Granite\",\"Limestone\",\"Marble\",\"Quartzite\",\"Sandstone\"],\"y\":[\"Basalt\",\"Coal\",\"Granite\",\"Limestone\",\"Marble\",\"Quartzite\",\"Sandstone\"],\"z\":[[5,3,1,0,3,0,0],[0,39,0,0,2,1,0],[0,0,10,2,0,1,1],[2,1,2,32,5,3,2],[2,1,0,4,27,12,0],[3,1,0,0,7,39,0],[0,2,1,4,4,5,38]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"5\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"3\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"3\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Basalt\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"39\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Coal\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"10\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Granite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"32\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"5\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"3\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Limestone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"4\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"27\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"12\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Marble\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"3\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"7\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"39\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Quartzite\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"\",\"x\":\"Basalt\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"2\",\"x\":\"Coal\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"1\",\"x\":\"Granite\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"4\",\"x\":\"Limestone\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"4\",\"x\":\"Marble\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"5\",\"x\":\"Quartzite\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"38\",\"x\":\"Sandstone\",\"xref\":\"x\",\"y\":\"Sandstone\",\"yref\":\"y\"},{\"font\":{\"color\":\"#094973\",\"size\":16},\"showarrow\":false,\"text\":\"True Class\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.1,\"yref\":\"paper\"},{\"font\":{\"color\":\"#094973\",\"size\":16},\"showarrow\":false,\"text\":\"Predicted Class\",\"textangle\":-90,\"x\":-0.17,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"width\":850,\"height\":550,\"margin\":{\"t\":100,\"l\":200}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d86b616e-7a79-400c-91cf-ffd5819d4c9e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Basalt': {'precision': 0.4166666666666667, 'recall': 0.4166666666666667, 'f1-score': 0.4166666666666667, 'support': 12}, 'Coal': {'precision': 0.9285714285714286, 'recall': 0.8297872340425532, 'f1-score': 0.8764044943820225, 'support': 47}, 'Granite': {'precision': 0.7142857142857143, 'recall': 0.7142857142857143, 'f1-score': 0.7142857142857143, 'support': 14}, 'Limestone': {'precision': 0.6808510638297872, 'recall': 0.7619047619047619, 'f1-score': 0.7191011235955055, 'support': 42}, 'Marble': {'precision': 0.5869565217391305, 'recall': 0.5625, 'f1-score': 0.5744680851063831, 'support': 48}, 'Quartzite': {'precision': 0.78, 'recall': 0.639344262295082, 'f1-score': 0.7027027027027027, 'support': 61}, 'Sandstone': {'precision': 0.7037037037037037, 'recall': 0.926829268292683, 'f1-score': 0.8000000000000002, 'support': 41}, 'accuracy': 0.7169811320754716, 'macro avg': {'precision': 0.6872907283994901, 'recall': 0.6930454153553516, 'f1-score': 0.6862326838198564, 'support': 265}, 'weighted avg': {'precision': 0.723941006486937, 'recall': 0.7169811320754716, 'f1-score': 0.7155946844412738, 'support': 265}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-239cf3ac18ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-c32ebe73e4a4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgs/cr.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Classification Report Image:\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imgs/cr.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Classification Report\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[1;32m    537\u001b[0m                                metadata={**default_metadata, **metadata})\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imgs/cr.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# read config file\n",
        "with open('config.json') as config_file:\n",
        "    default = json.load(config_file)\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "reset_random_seeds()\n",
        "print(f\"Default config:- {json.dumps(default, indent=2)}\\n P.S - Not used in sweeps.\\n\\n\")\n",
        "run = wandb.init(project=\"Whats-this-rockv2\",\n",
        "                    entity=\"rock-classifiers\",\n",
        "                    config=default, allow_val_change=True)\n",
        "config = wandb.config\n",
        "IMAGE_SIZE = (config[\"image_size\"], config[\"image_size\"])\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = get_generators(config)\n",
        "labels = ['Basalt', 'Coal', 'Granite', 'Limestone', 'Marble', 'Quartzite', 'Sandstone']\n",
        "config['num_classes'] = len(labels)\n",
        "\n",
        "model = train()\n",
        "evaluate()\n",
        "\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1XSy7JoKhvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e030d19-60a5-4005-c8bb-dc4c74371759"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Basalt': 0,\n",
              " 'Coal': 1,\n",
              " 'Granite': 2,\n",
              " 'Limestone': 3,\n",
              " 'Marble': 4,\n",
              " 'Quartzite': 5,\n",
              " 'Sandstone': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_dataset.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "id": "DqO7bjOd_56F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yXZZ9OEaXxv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Rock classifier training V2",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3fdcda2249d84838b2bceb2d0dded322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e49e29749644dfba9bad3725104ec47",
              "IPY_MODEL_302374ff7a6d4a739a1aebb9022185c7"
            ],
            "layout": "IPY_MODEL_a24ab6df6e054fc2ae1c8b383cd2227b"
          }
        },
        "9e49e29749644dfba9bad3725104ec47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db34859ac4794ab3a3ed7130fd0a2114",
            "placeholder": "​",
            "style": "IPY_MODEL_9e53f48761f44ebc97f91074dc64a598",
            "value": "272.993 MB of 272.993 MB uploaded (0.827 MB deduped)\r"
          }
        },
        "302374ff7a6d4a739a1aebb9022185c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3e470e0a6548f4972f3759ffa93274",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de29a88152a419cacf8f81ddd5c58bc",
            "value": 1
          }
        },
        "a24ab6df6e054fc2ae1c8b383cd2227b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db34859ac4794ab3a3ed7130fd0a2114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e53f48761f44ebc97f91074dc64a598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3e470e0a6548f4972f3759ffa93274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de29a88152a419cacf8f81ddd5c58bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}