{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bec1ffe6-cbc8-4e2e-9664-299eaedb0447",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5cc81e-dd72-40e1-a3bd-67f221f251a4",
   "metadata": {},
   "source": [
    "# Downloading Data\n",
    "\n",
    "> Downloading 4 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43fede-5ec4-4a25-8fe7-579c105e6238",
   "metadata": {},
   "source": [
    "## Downloading datasets\n",
    "### Dataset 1\n",
    "\n",
    "```bash\n",
    "kaggle datasets download salmaneunus/rock-classification --path data/0_raw/\n",
    "unzip -qn data/0_raw/rock-classification.zip -d data/1_extracted/\n",
    "mv -vn data/1_extracted/Dataset data/1_extracted/dataset1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a4602-0eb2-4b2c-aabb-3e389e5a1535",
   "metadata": {},
   "source": [
    "### Dataset 2\n",
    "\n",
    "```bash\n",
    "kaggle datasets download mahmoudalforawi/igneous-metamorphic-sedimentary-rocks-and-minerals --path data/0_raw/\n",
    "unzip -qn data/0_raw/igneous-metamorphic-sedimentary-rocks-and-minerals.zip -d data/1_extracted/\n",
    "mv data/1_extracted/Rock_Dataset data/1_extracted/dataset2\n",
    "\n",
    "rm -rf data/1_extracted/dataset2/minerals\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047ac0c-2dcc-4cf5-b316-6ba4fae65dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export data.utils\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "def timer_func(func):\n",
    "    \"\"\"Show the execution time of the function object passed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time()\n",
    "        print(f\"Function {func.__name__!r} executed in {(t2-t1):.4f}s\")\n",
    "        return result\n",
    "\n",
    "    return wrap_func\n",
    "\n",
    "\n",
    "def find_filepaths(root_folder: str):\n",
    "    \"\"\"Recursively finds all files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_folder : str\n",
    "        _description_\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for dirname, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            filepaths.append(os.path.join(dirname, filename))\n",
    "    return filepaths, len(filepaths)\n",
    "\n",
    "\n",
    "def get_new_name(dir_list: list) -> dict:\n",
    "    '''Return dict with old name and new name of files in multiple directories.\n",
    "\n",
    "    {'data/1_extracted/dataset1/Basalt/14.jpg': 'data/2_processed/Basalt/dataset1_01_Basalt_14.jpg'}\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dir_list : list\n",
    "        list of directories that needs to be combined\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {old_path: new_path}\n",
    "    '''\n",
    "    file_list = []\n",
    "    for dir in dir_list:\n",
    "        paths, _ = find_filepaths(dir)\n",
    "        file_list.extend(paths)\n",
    "    \n",
    "    count = 1\n",
    "    file_dict = {}\n",
    "    for file_path in file_list:\n",
    "        dataset = file_path.split('/')[-3]\n",
    "        class_name = file_path.split('/')[-2]\n",
    "        basename = os.path.basename(file_path)\n",
    "        file_name = os.path.splitext(basename)[0]\n",
    "        extension = os.path.splitext(basename)[1]\n",
    "        new_file_name = os.path.join('data','2_processed', class_name, f'{dataset}_{class_name}_{str(count).zfill(3)}_{file_name}{extension}')\n",
    "        file_dict[file_path] = new_file_name\n",
    "        count += 1\n",
    "\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d30cba-1723-40af-ac7a-e4dd7aa25480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export data.download\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from src.data.utils import timer_func, find_filepaths\n",
    "\n",
    "\n",
    "@timer_func\n",
    "def download_datasets():\n",
    "    \"\"\"Download the dataset with dataset_id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_id : int\n",
    "        Dataset number\n",
    "    \"\"\"\n",
    "    data_dict = {\n",
    "        1: {\"script\": \"src/scripts/dataset1.sh\", \"filecount\": 2083},\n",
    "        2: {\"script\": \"src/scripts/dataset2.sh\", \"filecount\": 4553},\n",
    "    }\n",
    "    for dataset_id in data_dict:\n",
    "        if not os.path.exists(\n",
    "            os.path.join(\"data\", \"1_extracted\", f\"dataset{dataset_id}\")\n",
    "        ):\n",
    "            print(f\"Downloading dataset {dataset_id}...\")\n",
    "            os.system(f\"sh {data_dict[dataset_id]['script']}\")\n",
    "        else:\n",
    "            _, count = find_filepaths(\n",
    "                os.path.join(\"data\", \"1_extracted\", f\"dataset{dataset_id}\")\n",
    "            )\n",
    "            assert count == data_dict[dataset_id][\"filecount\"]\n",
    "            print(f\"dataset{dataset_id} already exists.\")\n",
    "            print(f\"Total Files in dataset{dataset_id}:- {count}.\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c3c2c-064c-4554-b7fa-1db0053a4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export data.utils\n",
    "\n",
    "import shutil\n",
    "from src.data.utils import find_filepaths, get_new_name\n",
    "\n",
    "def move_to_processed():\n",
    "    dir1 = 'data/1_extracted/dataset1'\n",
    "    dir2 = 'data/1_extracted/dataset2'\n",
    "    for d1, d2 in zip(os.listdir(dir1), os.listdir(dir2)):\n",
    "        assert d1 == d2\n",
    "        path_dict = get_new_name([os.path.join(dir1, d1), os.path.join(dir2, d2)])\n",
    "        \n",
    "        for old_path, new_path in path_dict.items():\n",
    "            shutil.copy(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6f618-b807-4361-b943-3223f1ae5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "215557856cb2427135ee1299fe98091812eefded806e23b37d735190fbb4601b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
