{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd94e31-be5c-4db1-a011-1e75d0618d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97847666-05b1-4b85-b1b1-db6f4f9a741e",
   "metadata": {},
   "source": [
    "# Data utils\n",
    "\n",
    "> Data download and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d044e6a-4a84-48de-a009-62396a876c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# import imghdr\n",
    "# import os\n",
    "# import shutil\n",
    "# from time import time\n",
    "# from typing import Optional\n",
    "\n",
    "# import cv2\n",
    "# # # import keras_cv\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# # # import tensorflow as tf\n",
    "# # # from tensorflow.keras import applications, layers\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001c0ae-46fe-447b-b727-379e6add0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# def timer_func(func):\n",
    "#     \"\"\"Show the execution time of the function object passed.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     func : _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "\n",
    "#     def wrap_func(*args, **kwargs):\n",
    "#         t1 = time()\n",
    "#         result = func(*args, **kwargs)\n",
    "#         t2 = time()\n",
    "#         print(f\"Function {func.__name__!r} executed in {(t2-t1):.4f}s\")\n",
    "#         return result\n",
    "\n",
    "#     return wrap_func\n",
    "\n",
    "# def find_filepaths(root_folder: str):\n",
    "#     \"\"\"Recursively finds all files.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     root_folder : str\n",
    "#         _description_\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     filepaths = []\n",
    "#     for dirname, _, filenames in os.walk(root_folder):\n",
    "#         for filename in filenames:\n",
    "#             filepaths.append(os.path.join(dirname, filename))\n",
    "#     total_images_before_deletion = len(filepaths)\n",
    "#     print(f\"Total images before deletion = {total_images_before_deletion}\")\n",
    "#     return filepaths\n",
    "\n",
    "\n",
    "# def remove_unsupported_images(root_folder: str):\n",
    "#     \"\"\"Remove unsupported images.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     root_folder : str\n",
    "#         Root Folder.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n\\nRemoving unsupported images...\")\n",
    "#     count = 1\n",
    "#     filepaths = find_filepaths(root_folder)\n",
    "#     for filepath in filepaths:\n",
    "#         if filepath.endswith((\"JFIF\", \"webp\", \"jfif\")):\n",
    "#             shutil.move(\n",
    "#                 filepath,\n",
    "#                 os.path.join(\"data\", \"corrupted_images\", os.path.basename(filepath)),\n",
    "#             )\n",
    "#             count += 1\n",
    "#     print(f\"Removed {count} unsupported files.\")\n",
    "\n",
    "# @timer_func\n",
    "# def remove_corrupted_images(\n",
    "#     s_dir: str, ext_list: list = [\"jpg\", \"png\", \"jpeg\", \"gif\", \"bmp\", \"JPEG\"]\n",
    "# ):\n",
    "#     \"\"\"Remove corrupted images.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     s_dir : str\n",
    "#         Source directory.\n",
    "#     ext_list : list, optional\n",
    "#         Extensions list, by default [\"jpg\", \"png\", \"jpeg\", \"gif\", \"bmp\", \"JPEG\"]\n",
    "#     \"\"\"\n",
    "#     print(\"\\n\\nRemoving corrupted images...\")\n",
    "#     classes = os.listdir(s_dir)\n",
    "\n",
    "#     def remove_corrupted_from_dir(rock_class):\n",
    "#         # remove corrupted images from single directory\n",
    "#         bad_images = []\n",
    "#         class_path = os.path.join(s_dir, rock_class)\n",
    "#         print(f\"Processing class directory {rock_class}...\")\n",
    "#         if os.path.isdir(class_path):\n",
    "#             file_list = os.listdir(class_path)\n",
    "#             for f in file_list:\n",
    "#                 f_path = os.path.join(class_path, f)\n",
    "#                 tip = imghdr.what(f_path)\n",
    "#                 if ext_list.count(tip) == 0:\n",
    "#                     bad_images.append(f_path)\n",
    "#                 if os.path.isfile(f_path):\n",
    "#                     try:\n",
    "#                         cv2.imread(f_path)\n",
    "#                         # shape = img.shape\n",
    "#                     except Exception:\n",
    "#                         print(\"file \", f_path, \" is not a valid image file\")\n",
    "#                         bad_images.append(f_path)\n",
    "#                 else:\n",
    "#                     print(\n",
    "#                         \"*** fatal error, you a sub directory \",\n",
    "#                         f,\n",
    "#                         \" in class directory \",\n",
    "#                         rock_class,\n",
    "#                     )\n",
    "#         else:\n",
    "#             print(\n",
    "#                 \"*** WARNING*** you have files in \",\n",
    "#                 s_dir,\n",
    "#                 \" it should only contain sub directories\",\n",
    "#             )\n",
    "\n",
    "#         for f_path in bad_images:\n",
    "#             shutil.move(\n",
    "#                 f_path,\n",
    "#                 os.path.join(\"data\", \"corrupted_images\", os.path.basename(f_path)),\n",
    "#             )\n",
    "#         print(f\"removed {len(bad_images)} bad images from {rock_class}.\")\n",
    "\n",
    "#     # Multiprocessing\n",
    "#     # create all tasks\n",
    "#     from multiprocessing import Process\n",
    "\n",
    "#     processes = [Process(target=remove_corrupted_from_dir, args=(i,)) for i in classes]\n",
    "#     # start all processes\n",
    "#     for process in processes:\n",
    "#         process.start()\n",
    "#     # wait for all processes to complete\n",
    "#     for process in processes:\n",
    "#         process.join()\n",
    "#     # report that all tasks are completed\n",
    "#     print(\"Removed all corrupted images.\", flush=True)\n",
    "\n",
    "\n",
    "# def get_dims(file: str) -> Optional[tuple]:\n",
    "#     \"\"\"Return dimenstions for an RBG image.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     file : str\n",
    "#         file path for image\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     Optional[tuple, None]\n",
    "#         returns a tuple of heights and width of image or None\n",
    "#     \"\"\"\n",
    "#     im = cv2.imread(file)\n",
    "#     if im is not None:\n",
    "#         arr = np.array(im)\n",
    "#         h, w = arr.shape[0], arr.shape[1]\n",
    "#         return h, w\n",
    "#     elif im is None:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def get_df(root: str = \"data/2_processed\") -> pd.DataFrame:\n",
    "#     \"\"\"Return df with classes, image paths and file names.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     root : str, optional\n",
    "#         directory to scan for image files, by default \"data/2_processed\"\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         with columns file_name, class and file_path\n",
    "#     \"\"\"\n",
    "#     classes = os.listdir(root)\n",
    "\n",
    "#     class_names = []\n",
    "#     images_paths = []\n",
    "#     file_names = []\n",
    "\n",
    "#     for class_name in classes:\n",
    "#         for dirname, _, filenames in os.walk(os.path.join(root, class_name)):\n",
    "#             for file_name in filenames:\n",
    "#                 images_paths.append(os.path.join(root, class_name, file_name))\n",
    "#                 class_names.append(class_name)\n",
    "#                 file_names.append(file_name)\n",
    "\n",
    "#     df = pd.DataFrame(\n",
    "#         list(zip(file_names, class_names, images_paths)),\n",
    "#         columns=[\"file_name\", \"class\", \"file_path\"],\n",
    "#     )\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def get_value_counts(dataset_path: str) -> None:\n",
    "#     \"\"\"Get class counts of all classes in the dataset.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataset_path : str\n",
    "#         directory with subclasses\n",
    "#     \"\"\"\n",
    "#     data = get_df(dataset_path)\n",
    "#     vc = data[\"file_name\"].apply(lambda x: x.split(\".\")[-1]).value_counts()\n",
    "#     print(vc)\n",
    "\n",
    "\n",
    "# ####################################### tf.data Utilities ###################################\n",
    "\n",
    "\n",
    "# def scalar(img: Image) -> Image:\n",
    "#     \"\"\"Scale pixel between -1 and +1.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     img : Image\n",
    "#         PIL Image\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     Image\n",
    "#         imagew with pixel values scaled between -1 and 1\n",
    "#     \"\"\"\n",
    "#     return img / 127.5 - 1\n",
    "\n",
    "\n",
    "# def get_preprocess(cfg):\n",
    "#     \"\"\"Return preprocess function for particular model.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     cfg : cfg (omegaconf.DictConfig)\n",
    "#         Hydra Configuration\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     preprocess_dict = {\n",
    "#         # \"convnexttiny\":applications.convnext,\n",
    "#         \"vgg16\": applications.vgg16,\n",
    "#         \"resnet\": applications.resnet,\n",
    "#         \"inceptionresnetv2\": applications.inception_resnet_v2,\n",
    "#         \"mobilenetv2\": applications.mobilenet_v2,\n",
    "#         \"efficientnetv2\": applications.efficientnet_v2,\n",
    "#         \"efficientnetv2m\": applications.efficientnet_v2,\n",
    "#         \"xception\": applications.xception,\n",
    "#     }\n",
    "\n",
    "#     return preprocess_dict[cfg.backbone].preprocess_input\n",
    "\n",
    "\n",
    "# def prepare(ds, cfg, shuffle=False, augment=False):\n",
    "#     \"\"\"Prepare dataset using augment, preprocess, cache, shuffle and prefetch.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ds : _type_\n",
    "#         _description_\n",
    "#     cfg : cfg (omegaconf.DictConfig):\n",
    "#         Hydra Configuration\n",
    "#     shuffle : bool, optional\n",
    "#         _description_, by default False\n",
    "#     augment : bool, optional\n",
    "#         _description_, by default False\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     # keras_cv\n",
    "#     def to_dict(image, label):\n",
    "#         image = tf.image.resize(image, (cfg.image_size, cfg.image_size))\n",
    "#         image = tf.cast(image, tf.float32)\n",
    "#         # label = tf.one_hot(label, cfg.num_classes)\n",
    "#         return {\"images\": image, \"labels\": label}\n",
    "\n",
    "#     def preprocess_for_model(inputs):\n",
    "#         images, labels = inputs[\"images\"], inputs[\"labels\"]\n",
    "#         images = tf.cast(images, tf.float32)\n",
    "#         return images, labels\n",
    "\n",
    "#     def cut_mix_and_mix_up(samples):\n",
    "#         samples = cut_mix(samples, training=True)\n",
    "#         samples = mix_up(samples, training=True)\n",
    "#         return samples\n",
    "\n",
    "#     def apply_rand_augment(inputs):\n",
    "#         inputs[\"images\"] = rand_augment(inputs[\"images\"])\n",
    "#         return inputs\n",
    "\n",
    "#     AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#     if cfg.preprocess:\n",
    "#         preprocess_input = get_preprocess(cfg)\n",
    "#         ds = ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "#     if augment:\n",
    "#         # normal augmentation\n",
    "#         data_augmentation = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 layers.RandomFlip(\n",
    "#                     \"horizontal\",\n",
    "#                     input_shape=(cfg.image_size, cfg.image_size, cfg.image_channels),\n",
    "#                 ),\n",
    "#                 layers.RandomRotation(0.1),\n",
    "#                 layers.RandomZoom(0.1),\n",
    "#             ]\n",
    "#         )\n",
    "#         # Use data augmentation only on the training set.\n",
    "#         ds = ds.map(\n",
    "#             lambda x, y: (data_augmentation(x, training=True), y),\n",
    "#             num_parallel_calls=AUTOTUNE,\n",
    "#         )\n",
    "#     elif augment == \"kerascv\":\n",
    "#         # using keras_cv\n",
    "#         ds = ds.map(to_dict, num_parallel_calls=AUTOTUNE)\n",
    "#         rand_augment = keras_cv.layers.RandAugment(\n",
    "#             value_range=(0, 255),\n",
    "#             augmentations_per_image=3,\n",
    "#             magnitude=0.3,\n",
    "#             magnitude_stddev=0.2,\n",
    "#             rate=0.5,\n",
    "#         )\n",
    "#         cut_mix = keras_cv.layers.CutMix()\n",
    "#         mix_up = keras_cv.layers.MixUp()\n",
    "\n",
    "#         ds = ds.map(apply_rand_augment, num_parallel_calls=AUTOTUNE).map(\n",
    "#             cut_mix_and_mix_up, num_parallel_calls=AUTOTUNE\n",
    "#         )\n",
    "\n",
    "#         ds = ds.map(preprocess_for_model, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "#     ds = ds.cache()\n",
    "#     if shuffle:\n",
    "#         ds = ds.shuffle(buffer_size=1000)\n",
    "\n",
    "#     # # Batch all datasets.\n",
    "#     # ds = ds.batch(cfg.batch_size)\n",
    "\n",
    "#     # Use buffered prefetching on all datasets.\n",
    "#     return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# def get_tfds_from_dir(cfg):\n",
    "#     \"\"\"Convert directory of images to tfds dataset.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     cfg : cfg (omegaconf.DictConfig):\n",
    "#         Hydra Configuration\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     _type_\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     IMAGE_SIZE = (cfg.image_size, cfg.image_size)\n",
    "#     train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         \"data/4_tfds_dataset/train\",\n",
    "#         labels=\"inferred\",\n",
    "#         label_mode=\"categorical\",\n",
    "#         color_mode=\"rgb\",\n",
    "#         batch_size=cfg.batch_size,\n",
    "#         image_size=IMAGE_SIZE,\n",
    "#         shuffle=True,\n",
    "#         seed=cfg.seed,\n",
    "#         # subset='training'\n",
    "#     )\n",
    "\n",
    "#     val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         \"data/4_tfds_dataset/val\",\n",
    "#         labels=\"inferred\",\n",
    "#         label_mode=\"categorical\",\n",
    "#         color_mode=\"rgb\",\n",
    "#         batch_size=cfg.batch_size,\n",
    "#         image_size=IMAGE_SIZE,\n",
    "#         shuffle=True,\n",
    "#         seed=cfg.seed,\n",
    "#         # subset='validation'\n",
    "#     )\n",
    "\n",
    "#     test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#         \"data/4_tfds_dataset/test\",\n",
    "#         labels=\"inferred\",\n",
    "#         label_mode=\"categorical\",\n",
    "#         color_mode=\"rgb\",\n",
    "#         batch_size=cfg.batch_size,\n",
    "#         image_size=IMAGE_SIZE,\n",
    "#         shuffle=False,\n",
    "#         seed=cfg.seed,\n",
    "#         # subset='validation'\n",
    "#     )\n",
    "\n",
    "#     return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "# def rename_files(source_dir: str = \"data/2_processed/tmp\"):\n",
    "#     \"\"\"Rename files in classes and moves to 2_processed.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     source_dir : str, optional\n",
    "#         _description_, by default \"data/2_processed/tmp\"\n",
    "#     \"\"\"\n",
    "#     class_names = os.listdir(source_dir)\n",
    "#     for class_name in class_names:\n",
    "#         class_path = os.path.join(source_dir, class_name)\n",
    "#         dest_path = os.path.join(\"data/2_processed\", class_name)\n",
    "#         count = len(os.listdir(dest_path)) + 1\n",
    "#         for filename in os.listdir(class_path):\n",
    "#             old_path = os.path.join(source_dir, class_name, filename)\n",
    "#             _, extension = os.path.splitext(filename)\n",
    "#             new_name = f\"{class_name}_{count}{extension}\"\n",
    "#             new_path = os.path.join(dest_path, new_name)\n",
    "#             shutil.copy(old_path, new_path)\n",
    "#             count += 1\n",
    "\n",
    "\n",
    "# def move_files(src_dir: str, dest_dir: str = \"data/2_processed/tmp\"):\n",
    "#     \"\"\"Move files to tmp directory in 2_processed.\n",
    "\n",
    "#     src_dir: directory of rock subclass with files [Basalt, Marble, Coal, ...]\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     src_dir : str\n",
    "#         _description_\n",
    "#     dest_dir : str, optional\n",
    "#         _description_, by default \"data/2_processed/tmp\"\n",
    "#     \"\"\"\n",
    "#     if os.path.exists(dest_dir):\n",
    "#         shutil.rmtree(dest_dir)\n",
    "#     os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "#     src_dir_name = os.path.basename(src_dir)\n",
    "#     dest_dir_path = os.path.join(dest_dir, src_dir_name.capitalize())\n",
    "#     os.makedirs(dest_dir_path, exist_ok=True)\n",
    "\n",
    "#     files = os.listdir(src_dir)\n",
    "#     total = len(files)\n",
    "#     for index, filename in tqdm(\n",
    "#         enumerate(files), desc=f\"Moving {src_dir_name}\", total=total\n",
    "#     ):\n",
    "#         src_path = os.path.join(src_dir, filename)\n",
    "#         dest_path = os.path.join(dest_dir_path, filename)\n",
    "#         # print(\"Copying\", src_path, dest_path)\n",
    "#         shutil.copy(src_path, dest_path)\n",
    "#         # print(f\"Moved {index+1} files from {src_dir} to {dest_dir_path}\")\n",
    "\n",
    "\n",
    "# def move_and_rename(class_dir: str):\n",
    "#     \"\"\"Move files from class_dir to tmp, renames them there based on count, and moves back to 2_processed class_dir: A class dir of supporting classes (Marble, Coal, ...), which contains image files.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     class_dir : str\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     target_classes = os.listdir(\"data/2_processed/\")\n",
    "#     if \"tmp\" in target_classes:\n",
    "#         target_classes.remove(\"tmp\")\n",
    "#     target_classes_lower = list(map(lambda x: x.lower(), target_classes))\n",
    "\n",
    "#     for subclass_dir in os.listdir(class_dir):\n",
    "#         if subclass_dir.lower() in target_classes_lower:\n",
    "#             subclass_dir_path = os.path.join(class_dir, subclass_dir)\n",
    "#             move_files(subclass_dir_path)\n",
    "#             rename_files()\n",
    "#             shutil.rmtree(\"data/2_processed/tmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b91db-4883-4318-93d8-0cc19afabfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d714610-e013-4aae-8aa8-39663812c4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
