{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHpZwQ6o3r1q"
      },
      "source": [
        "# Notes\n",
        "\n",
        "\n",
        "```\n",
        "augmentation: True\n",
        "\tbackbone: resnet\n",
        "\tbatch_size: 64\n",
        "\tclass_weights: True\n",
        "\tdata_path: data/4_tfds_dataset/\n",
        "\tdataset_id: [1]\n",
        "\tdropout_rate: 0.3\n",
        "\tearlystopping_patience: 20\n",
        "\tepochs: 100\n",
        "\timage_channels: 3\n",
        "\timage_size: 224\n",
        "\tloss: categorical_crossentropy\n",
        "\tlr: 0.0001\n",
        "\tmetrics: ['accuracy']\n",
        "\tmonitor: val_accuracy\n",
        "\tnotes: \n",
        "\tnum_classes: 7\n",
        "\toptimizer: adam\n",
        "\tpreprocess: True\n",
        "\tproject: Whats-this-rockv3\n",
        "\treduce_lr_factor: 0.5\n",
        "\treduce_lr_min_lr: 1e-05\n",
        "\treduce_lr_patience: 7\n",
        "\tsampling: undersampling\n",
        "\tsave_model: False\n",
        "\tseed: 42\n",
        "\ttrainable: False\n",
        "\tuse_earlystopping: True\n",
        "\tuse_pretrained_weights: True\n",
        "\tuse_reduce_lr: True\n",
        "\tuse_wandb: True\n",
        "\twand_mode: online\n",
        "```\n",
        "\n",
        "\n",
        "- remove corrupted images - Takes 18 secs\n",
        "- Try undersampling with this, and all models\n",
        "        python src/models/train.py 'notes=\"finetuning, mode:max\"' \\\n",
        "                            wandb.project=Whats-this-rockv3 \\\n",
        "                            dataset.id=[1] \\\n",
        "                            dataset.sampling=oversampling \\\n",
        "                            epochs=50 \\\n",
        "                            lr=1e-2 \\\n",
        "                            optimizer=adamax \\\n",
        "                            model.backbone=mobilenetv2 \\\n",
        "                            model.dropout_rate=0.2 \\\n",
        "                            model.trainable=False \\\n",
        "                            callback.reduce_lr.use=False \\\n",
        "                            callback.earlystopping.patience=20 \\\n",
        "                            model.save_model=False\n",
        "- improve using these\n",
        "    - [Finetuning Efficientnet](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/image_classification_efficientnet_fine_tuning.ipynb#scrollTo=1KvkMvLI0iCh)\n",
        "    - [Wandb Article](https://wandb.ai/stacey/mendeleev/reports/Tables-Tutorial-Visualize-Data-for-Image-Classification--VmlldzozNjE3NjA)\n",
        "    - [bloodMNIST](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/Keras_pipeline_with_Weights_and_Biases.ipynb#scrollTo=-303Shsata7Z)\n",
        "\n",
        "    - [Simpsons classification](https://colab.research.google.com/drive/181GCGp36_75C2zm7WLxr9U2QjMXXoibt#scrollTo=xftEwKyuaJ5q)\n",
        "\n",
        "## Efficientnet Finetuning Notes\n",
        "\n",
        "- too low- [0.000001, 0.000005, 0.00005]\n",
        "- too high [0.002, 0.005]\n",
        "- 0.001, 0.0005 works\n",
        "    - why?\n",
        "    - isn't it too high for finetuning?\n",
        "\n",
        "## Efficientnet to do\n",
        "- should lr be min max or a list [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
        "- freeze parameter - [true. false]\n",
        "    - so 2 best models, one with freeze true and another with freeze false\n",
        "    - [freeze: true best model](https://wandb.ai/rock-classifiers/Whats-this-rockv2/runs/9fgg9eua?workspace=user-udaylunawat)\n",
        "        \n",
        "    val_accuracy - 63.9\n",
        "\n",
        "    val_f1_score - 63.4\n",
        "            earlystopping_patience 3\n",
        "            freeze true\n",
        "            lr 0.00007\n",
        "            lr_reduce_factor 0.9\n",
        "            lr_reduce_patience 1\n",
        "    - [freeze: false best model](https://wandb.ai/rock-classifiers/Whats-this-rockv2/runs/4qmss0xh/overview?workspace=user-udaylunawat)\n",
        "    \n",
        "    val_accuracy:-0.74\n",
        "    \n",
        "    val_f1_score:-0.73\n",
        "\n",
        "            lr:- 0.0003\n",
        "            reduce_factor: 0.3\n",
        "            lr_reduce_patience:- 3\n",
        "            earlystopping_patience:- 10\n",
        "\n",
        "    - finetune both models in another sweep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUSuNjlQZSi-"
      },
      "source": [
        "# Clone Repo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "i2bWogl5nNX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b6f8ab-97af-49e4-c002-675eb1209e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 18 12:04:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3CTmNjsIAIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503d5952-f489-40f8-d89e-e235471ac24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/Whats-this-rock/'\n",
            "/content\n",
            "Cloning into 'Whats-this-rock'...\n",
            "remote: Enumerating objects: 2241, done.\u001b[K\n",
            "remote: Counting objects: 100% (481/481), done.\u001b[K\n",
            "remote: Compressing objects: 100% (236/236), done.\u001b[K\n",
            "remote: Total 2241 (delta 242), reused 411 (delta 242), pack-reused 1760\u001b[K\n",
            "Receiving objects: 100% (2241/2241), 5.85 MiB | 19.64 MiB/s, done.\n",
            "Resolving deltas: 100% (1445/1445), done.\n",
            "/content/Whats-this-rock\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!rm -rf /content/Whats-this-rock/\n",
        "# !git clone https://github.com/udaylunawat/Whats-this-rock.git\n",
        "!git clone -b hydra https://github.com/udaylunawat/Whats-this-rock.git\n",
        "%cd /content/Whats-this-rock/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluating Model"
      ],
      "metadata": {
        "id": "RSk5wNo6SAS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "H5UlUGLqCDgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_MODE'] = 'online' # offline\n",
        "\n",
        "if 'WANDB_API_KEY' not in os.environ:\n",
        "    if os.environ['WANDB_MODE'] == 'online':\n",
        "        from getpass import getpass\n",
        "        secret = getpass('Enter WandB API Key: ')\n",
        "        os.environ['WANDB_API_KEY'] = secret\n",
        "    else:\n",
        "        print(\"WandB Offline!\")"
      ],
      "metadata": {
        "id": "pYQG09V4qSUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7c40c4-cec2-47f4-d55b-f3665f3aeba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WandB API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh src/scripts/setup.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apf7XZRZZN6W",
        "outputId": "3d2b40e3-bafd-4ae1-eeee-e461d2c20c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "(Reading database ... 155569 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155547 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 35.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 71.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 64.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 78.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.2 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "renamed 'kaggle.json' -> '/root/.kaggle/kaggle.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY8_QWOvmXZk",
        "outputId": "a130cf9f-6b7a-4ee0-de4f-c2417342f479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKG91Awf_DVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eceaf2e-c28e-4024-966d-ae0c83f4f582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./src)... Done. 0.1s\n",
            "\n",
            "Datasets used for Training:- [1, 2, 3, 4]\n",
            "Downloading rock-classification.zip to data/0_raw\n",
            " 92% 146M/159M [00:05<00:00, 31.6MB/s]\n",
            "100% 159M/159M [00:05<00:00, 31.4MB/s]\n",
            "renamed 'data/1_extracted/Dataset' -> 'data/1_extracted/dataset1'\n",
            "Downloading igneous-metamorphic-sedimentary-rocks-and-minerals.zip to data/0_raw\n",
            " 96% 337M/349M [00:11<00:00, 34.1MB/s]\n",
            "100% 349M/349M [00:11<00:00, 32.4MB/s]\n",
            "Downloading rocks-dataset.zip to data/0_raw\n",
            " 98% 585M/595M [00:29<00:00, 24.5MB/s]\n",
            "100% 595M/595M [00:29<00:00, 21.2MB/s]\n",
            "\n",
            "Processing dataset3\n",
            "Moving Granite: 100% 45/45 [00:00<00:00, 10244.45it/s]\n",
            "Moving Limestone: 100% 57/57 [00:00<00:00, 11296.85it/s]\n",
            "Moving Quartzite: 100% 64/64 [00:00<00:00, 12052.60it/s]\n",
            "Moving Marble: 100% 70/70 [00:00<00:00, 12021.51it/s]\n",
            "Moving Basalt: 100% 39/39 [00:00<00:00, 11027.23it/s]\n",
            "Moving Sandstone: 100% 47/47 [00:00<00:00, 11814.94it/s]\n",
            "Moving Granite: 100% 20/20 [00:00<00:00, 9873.60it/s]\n",
            "Moving Limestone: 100% 23/23 [00:00<00:00, 9834.74it/s]\n",
            "Moving Quartzite: 100% 17/17 [00:00<00:00, 9478.02it/s]\n",
            "Moving Marble: 100% 19/19 [00:00<00:00, 9703.13it/s]\n",
            "Moving Basalt: 100% 13/13 [00:00<00:00, 8894.94it/s]\n",
            "Moving Sandstone: 100% 19/19 [00:00<00:00, 10251.06it/s]\n",
            "\n",
            "Processing dataset4\n",
            "Moving Coal: 100% 45/45 [00:00<00:00, 3701.07it/s]\n",
            "Moving Granite: 100% 60/60 [00:00<00:00, 1555.37it/s]\n",
            "Moving Limestone: 100% 52/52 [00:00<00:00, 2352.84it/s]\n",
            "Moving Quartzite: 100% 58/58 [00:00<00:00, 3228.66it/s]\n",
            "Moving Marble: 100% 59/59 [00:00<00:00, 1967.18it/s]\n",
            "Moving Basalt: 100% 50/50 [00:00<00:00, 1391.73it/s]\n",
            "Moving Sandstone: 100% 58/58 [00:00<00:00, 1542.32it/s]\n",
            "\n",
            "Processing dataset1\n",
            "Moving Granite: 100% 101/101 [00:00<00:00, 3295.48it/s]\n",
            "Moving Basalt: 100% 86/86 [00:00<00:00, 3323.66it/s]\n",
            "Moving Coal: 100% 369/369 [00:00<00:00, 5474.41it/s]\n",
            "Moving Limestone: 100% 338/338 [00:00<00:00, 5776.76it/s]\n",
            "Moving Sandstone: 100% 325/325 [00:00<00:00, 4265.61it/s]\n",
            "Moving Quartzite: 100% 477/477 [00:00<00:00, 5974.58it/s]\n",
            "Moving Marble: 100% 387/387 [00:00<00:00, 9625.84it/s]\n",
            "\n",
            "Processing dataset2\n",
            "Moving granite: 100% 113/113 [00:00<00:00, 10523.48it/s]\n",
            "Moving Basalt: 100% 94/94 [00:00<00:00, 10936.30it/s]\n",
            "Moving quartzite: 100% 40/40 [00:00<00:00, 11490.46it/s]\n",
            "Moving marble: 100% 40/40 [00:00<00:00, 9098.77it/s]\n",
            "Moving Limestone: 100% 114/114 [00:00<00:00, 10482.77it/s]\n",
            "Moving coal: 100% 100/100 [00:00<00:00, 11207.23it/s]\n",
            "Moving Sandstone: 100% 45/45 [00:00<00:00, 9102.66it/s]\n",
            "\n",
            "Files other than jpg and png.\n",
            "\n",
            "\n",
            "data/2_processed:\n",
            "Basalt\n",
            "Coal\n",
            "Granite\n",
            "Limestone\n",
            "Marble\n",
            "Quartzite\n",
            "Sandstone\n",
            "\n",
            "data/2_processed/Basalt:\n",
            "\n",
            "data/2_processed/Coal:\n",
            "Coal_113.jpeg\n",
            "Coal_122.jpeg\n",
            "Coal_127.jpeg\n",
            "Coal_138.jpeg\n",
            "Coal_156.jpeg\n",
            "Coal_172.jpeg\n",
            "Coal_178.jpeg\n",
            "Coal_207.jpeg\n",
            "Coal_228.jpeg\n",
            "Coal_247.jpeg\n",
            "Coal_250.jpeg\n",
            "Coal_273.jpeg\n",
            "Coal_280.jpeg\n",
            "Coal_297.jpeg\n",
            "Coal_310.jpeg\n",
            "Coal_333.jpeg\n",
            "Coal_365.jpeg\n",
            "Coal_408.jpeg\n",
            "Coal_411.jpeg\n",
            "Coal_80.jpeg\n",
            "Coal_90.jpeg\n",
            "\n",
            "data/2_processed/Granite:\n",
            "Granite_127.JPEG\n",
            "Granite_142.JPEG\n",
            "Granite_162.JPEG\n",
            "Granite_163.JPEG\n",
            "Granite_164.JPEG\n",
            "Granite_168.JPEG\n",
            "Granite_178.JPEG\n",
            "Granite_179.JPEG\n",
            "Granite_181.JPEG\n",
            "Granite_184.JPEG\n",
            "Granite_186.JPEG\n",
            "Granite_187.JPEG\n",
            "Granite_192.jpeg\n",
            "Granite_193.JPEG\n",
            "Granite_201.JPEG\n",
            "Granite_202.JPEG\n",
            "Granite_205.JPEG\n",
            "Granite_211.jpeg\n",
            "Granite_214.JPEG\n",
            "Granite_217.JPEG\n",
            "Granite_220.JPEG\n",
            "Granite_224.JPEG\n",
            "\n",
            "data/2_processed/Limestone:\n",
            "Limestone_183.jfif\n",
            "Limestone_212.webp\n",
            "Limestone_216.jfif\n",
            "Limestone_226.webp\n",
            "Limestone_228.jpeg\n",
            "Limestone_229.jfif\n",
            "Limestone_230.jpeg\n",
            "Limestone_241.jfif\n",
            "Limestone_254.jpeg\n",
            "Limestone_264.jpeg\n",
            "Limestone_283.jfif\n",
            "Limestone_443.jpeg\n",
            "\n",
            "data/2_processed/Marble:\n",
            "Marble_160.webp\n",
            "Marble_237.jfif\n",
            "Marble_365.jfif\n",
            "Marble_427.webp\n",
            "\n",
            "data/2_processed/Quartzite:\n",
            "Quartzite_457.webp\n",
            "\n",
            "data/2_processed/Sandstone:\n",
            "Sandstone_183.webp\n",
            "Sandstone_229.webp\n",
            "\n",
            "\n",
            "File types before cleaning:\n",
            "jpg     2983\n",
            "png      399\n",
            "jpeg      28\n",
            "JPEG      20\n",
            "jfif       7\n",
            "webp       7\n",
            "Name: file_name, dtype: int64\n",
            "\n",
            "\n",
            "Removing unsupported images...\n",
            "Total images before deletion = 3444\n",
            "Removed 15 unsupported files.\n",
            "\n",
            "\n",
            "Removing corrupted images...\n",
            "processing class directory  Coal\n",
            "file  data/2_processed/Coal/Coal_436.jpg  is not a valid image file\n",
            "file  data/2_processed/Coal/Coal_379.jpg  is not a valid image file\n",
            "processing class directory  Granite\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "processing class directory  Limestone\n",
            "processing class directory  Quartzite\n",
            "processing class directory  Marble\n",
            "processing class directory  Basalt\n",
            "processing class directory  Sandstone\n",
            "removed 46 bad images.\n",
            "\n",
            "Function 'remove_corrupted_images' executed in 15.6555s\n",
            "\n",
            "File types after cleaning:\n",
            "jpg     2959\n",
            "png      398\n",
            "jpeg      25\n",
            "JPEG       2\n",
            "Name: file_name, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3384 entries, 0 to 3383\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  3384 non-null   object\n",
            " 1   class      3384 non-null   object\n",
            " 2   file_path  3384 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 79.4+ KB\n",
            "\n",
            " None \n",
            "\n",
            "Quartzite    654\n",
            "Limestone    573\n",
            "Marble       571\n",
            "Coal         506\n",
            "Sandstone    491\n",
            "Granite      316\n",
            "Basalt       273\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Splitting files in Train, Validation and Test and saving to data/4_tfds_dataset/\n",
            "0.75 0.125 0.125\n",
            "No Sampling.\n",
            "Copying files: 3384 files [00:00, 3895.26 files/s]\n",
            "\n",
            "\n",
            "\n",
            "Found 2535 files belonging to 7 classes.\n",
            "Found 420 files belonging to 7 classes.\n",
            "Found 429 files belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,965,191\n",
            "Trainable params: 2,377,479\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "\n",
            "Model loaded: resnet.\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "[2022-09-18 12:25:44,197][tensorflow][WARNING] - From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "Epoch 1/50\n",
            "159/159 [==============================] - 45s 49ms/step - loss: 1.7609 - accuracy: 0.3440 - val_loss: 1.3074 - val_accuracy: 0.5476 - lr: 5.0000e-04\n",
            "Epoch 2/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 1.4229 - accuracy: 0.4659 - val_loss: 1.1395 - val_accuracy: 0.5905 - lr: 5.0000e-04\n",
            "Epoch 3/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 1.2548 - accuracy: 0.5436 - val_loss: 1.0662 - val_accuracy: 0.6381 - lr: 5.0000e-04\n",
            "Epoch 4/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 1.1518 - accuracy: 0.5767 - val_loss: 1.0239 - val_accuracy: 0.6405 - lr: 5.0000e-04\n",
            "Epoch 5/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 1.0605 - accuracy: 0.6146 - val_loss: 1.0180 - val_accuracy: 0.6429 - lr: 5.0000e-04\n",
            "Epoch 6/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.9860 - accuracy: 0.6489 - val_loss: 0.9666 - val_accuracy: 0.6810 - lr: 5.0000e-04\n",
            "Epoch 7/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.9090 - accuracy: 0.6738 - val_loss: 0.9386 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 8/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.8425 - accuracy: 0.7014 - val_loss: 0.9333 - val_accuracy: 0.6857 - lr: 5.0000e-04\n",
            "Epoch 9/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.7927 - accuracy: 0.7298 - val_loss: 0.8839 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 10/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.7179 - accuracy: 0.7440 - val_loss: 0.9481 - val_accuracy: 0.6881 - lr: 5.0000e-04\n",
            "Epoch 11/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.6791 - accuracy: 0.7578 - val_loss: 0.9002 - val_accuracy: 0.6929 - lr: 5.0000e-04\n",
            "Epoch 12/50\n",
            "157/159 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.7859\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00035000001662410796.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.6069 - accuracy: 0.7866 - val_loss: 0.9106 - val_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 13/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.5422 - accuracy: 0.8051 - val_loss: 0.9132 - val_accuracy: 0.6952 - lr: 3.5000e-04\n",
            "Epoch 14/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.5026 - accuracy: 0.8264 - val_loss: 0.9049 - val_accuracy: 0.7048 - lr: 3.5000e-04\n",
            "Epoch 15/50\n",
            "157/159 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.8418\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00024500001163687554.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.4707 - accuracy: 0.8406 - val_loss: 0.9612 - val_accuracy: 0.6833 - lr: 3.5000e-04\n",
            "Epoch 16/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.4252 - accuracy: 0.8556 - val_loss: 0.9362 - val_accuracy: 0.7071 - lr: 2.4500e-04\n",
            "Epoch 17/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.3982 - accuracy: 0.8596 - val_loss: 0.9332 - val_accuracy: 0.7143 - lr: 2.4500e-04\n",
            "Epoch 18/50\n",
            "158/159 [============================>.] - ETA: 0s - loss: 0.3680 - accuracy: 0.8785\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00017150000203400848.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.3672 - accuracy: 0.8789 - val_loss: 0.9529 - val_accuracy: 0.7143 - lr: 2.4500e-04\n",
            "Epoch 19/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.3381 - accuracy: 0.8884 - val_loss: 0.9493 - val_accuracy: 0.7214 - lr: 1.7150e-04\n",
            "Epoch 20/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.3220 - accuracy: 0.8978 - val_loss: 0.9583 - val_accuracy: 0.7190 - lr: 1.7150e-04\n",
            "Epoch 21/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.3180 - accuracy: 0.8970 - val_loss: 0.9665 - val_accuracy: 0.7262 - lr: 1.7150e-04\n",
            "Epoch 22/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.3035 - accuracy: 0.9018 - val_loss: 0.9856 - val_accuracy: 0.7190 - lr: 1.7150e-04\n",
            "Epoch 23/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.2940 - accuracy: 0.8978 - val_loss: 0.9782 - val_accuracy: 0.7286 - lr: 1.7150e-04\n",
            "Epoch 24/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2669 - accuracy: 0.9120 - val_loss: 1.0121 - val_accuracy: 0.7143 - lr: 1.7150e-04\n",
            "Epoch 25/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2527 - accuracy: 0.9179 - val_loss: 1.0274 - val_accuracy: 0.7071 - lr: 1.7150e-04\n",
            "Epoch 26/50\n",
            "159/159 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9160\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00012004999734926967.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2560 - accuracy: 0.9160 - val_loss: 1.0293 - val_accuracy: 0.7143 - lr: 1.7150e-04\n",
            "Epoch 27/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2352 - accuracy: 0.9247 - val_loss: 1.0383 - val_accuracy: 0.7167 - lr: 1.2005e-04\n",
            "Epoch 28/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2340 - accuracy: 0.9302 - val_loss: 1.0338 - val_accuracy: 0.7143 - lr: 1.2005e-04\n",
            "Epoch 29/50\n",
            "158/159 [============================>.] - ETA: 0s - loss: 0.2294 - accuracy: 0.9258\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 8.403499814448878e-05.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2296 - accuracy: 0.9254 - val_loss: 1.0396 - val_accuracy: 0.7190 - lr: 1.2005e-04\n",
            "Epoch 30/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2192 - accuracy: 0.9286 - val_loss: 1.0613 - val_accuracy: 0.7024 - lr: 8.4035e-05\n",
            "Epoch 31/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2014 - accuracy: 0.9424 - val_loss: 1.0575 - val_accuracy: 0.7286 - lr: 8.4035e-05\n",
            "Epoch 32/50\n",
            "159/159 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.9290\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 5.882449768250808e-05.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.2111 - accuracy: 0.9290 - val_loss: 1.0692 - val_accuracy: 0.7167 - lr: 8.4035e-05\n",
            "Epoch 33/50\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.1988 - accuracy: 0.9436 - val_loss: 1.0716 - val_accuracy: 0.7167 - lr: 5.8824e-05\n",
            "Epoch 34/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1935 - accuracy: 0.9369 - val_loss: 1.0584 - val_accuracy: 0.7214 - lr: 5.8824e-05\n",
            "Epoch 35/50\n",
            "158/159 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9436\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1896 - accuracy: 0.9440 - val_loss: 1.0681 - val_accuracy: 0.7143 - lr: 5.8824e-05\n",
            "Epoch 36/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1904 - accuracy: 0.9436 - val_loss: 1.0697 - val_accuracy: 0.7238 - lr: 5.0000e-05\n",
            "Epoch 37/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1801 - accuracy: 0.9460 - val_loss: 1.0667 - val_accuracy: 0.7119 - lr: 5.0000e-05\n",
            "Epoch 38/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1585 - accuracy: 0.9554 - val_loss: 1.0810 - val_accuracy: 0.7238 - lr: 5.0000e-05\n",
            "Epoch 39/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1763 - accuracy: 0.9491 - val_loss: 1.0905 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
            "Epoch 40/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1791 - accuracy: 0.9440 - val_loss: 1.0836 - val_accuracy: 0.7190 - lr: 5.0000e-05\n",
            "Epoch 41/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1766 - accuracy: 0.9491 - val_loss: 1.0921 - val_accuracy: 0.7238 - lr: 5.0000e-05\n",
            "Epoch 42/50\n",
            "159/159 [==============================] - 5s 29ms/step - loss: 0.1740 - accuracy: 0.9519 - val_loss: 1.0859 - val_accuracy: 0.7286 - lr: 5.0000e-05\n",
            "Epoch 43/50\n",
            "157/159 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9489Restoring model weights from the end of the best epoch: 23.\n",
            "159/159 [==============================] - 5s 30ms/step - loss: 0.1717 - accuracy: 0.9483 - val_loss: 1.0849 - val_accuracy: 0.7286 - lr: 5.0000e-05\n",
            "Epoch 43: early stopping\n",
            "\n",
            "Finetuning model with BatchNorm layers freezed.\n",
            "\n",
            "conv5_block2_1_conv True\n",
            "conv5_block2_1_bn False\n",
            "conv5_block2_1_relu True\n",
            "conv5_block2_2_conv True\n",
            "conv5_block2_2_bn False\n",
            "conv5_block2_2_relu True\n",
            "conv5_block2_3_conv True\n",
            "conv5_block2_3_bn False\n",
            "conv5_block2_add True\n",
            "conv5_block2_out True\n",
            "conv5_block3_1_conv True\n",
            "conv5_block3_1_bn False\n",
            "conv5_block3_1_relu True\n",
            "conv5_block3_2_conv True\n",
            "conv5_block3_2_bn False\n",
            "conv5_block3_2_relu True\n",
            "conv5_block3_3_conv True\n",
            "conv5_block3_3_bn False\n",
            "conv5_block3_add True\n",
            "conv5_block3_out True\n",
            "\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,965,191\n",
            "Trainable params: 25,899,783\n",
            "Non-trainable params: 65,408\n",
            "_________________________________________________________________\n",
            "Epoch 44/60\n",
            "159/159 - 27s - loss: 0.8324 - accuracy: 0.7207 - val_loss: 1.1327 - val_accuracy: 0.6595 - lr: 1.0000e-05 - 27s/epoch - 172ms/step\n",
            "Epoch 45/60\n",
            "159/159 - 15s - loss: 0.6192 - accuracy: 0.7874 - val_loss: 1.1993 - val_accuracy: 0.6381 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 46/60\n",
            "159/159 - 15s - loss: 0.5450 - accuracy: 0.8138 - val_loss: 1.2198 - val_accuracy: 0.6405 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 47/60\n",
            "159/159 - 15s - loss: 0.4568 - accuracy: 0.8410 - val_loss: 1.2428 - val_accuracy: 0.6381 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 48/60\n",
            "159/159 - 15s - loss: 0.4027 - accuracy: 0.8718 - val_loss: 1.2589 - val_accuracy: 0.6262 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 49/60\n",
            "159/159 - 15s - loss: 0.3447 - accuracy: 0.8911 - val_loss: 1.2239 - val_accuracy: 0.6333 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 50/60\n",
            "159/159 - 15s - loss: 0.3079 - accuracy: 0.8923 - val_loss: 1.2870 - val_accuracy: 0.6310 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 51/60\n",
            "159/159 - 15s - loss: 0.2682 - accuracy: 0.9156 - val_loss: 1.2865 - val_accuracy: 0.6405 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 52/60\n",
            "159/159 - 15s - loss: 0.2330 - accuracy: 0.9247 - val_loss: 1.3360 - val_accuracy: 0.6333 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 53/60\n",
            "159/159 - 15s - loss: 0.2233 - accuracy: 0.9333 - val_loss: 1.3290 - val_accuracy: 0.6357 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 54/60\n",
            "159/159 - 15s - loss: 0.1981 - accuracy: 0.9381 - val_loss: 1.3734 - val_accuracy: 0.6333 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 55/60\n",
            "159/159 - 15s - loss: 0.1607 - accuracy: 0.9574 - val_loss: 1.3955 - val_accuracy: 0.6405 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 56/60\n",
            "159/159 - 15s - loss: 0.1412 - accuracy: 0.9594 - val_loss: 1.4365 - val_accuracy: 0.6357 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 57/60\n",
            "159/159 - 16s - loss: 0.1330 - accuracy: 0.9617 - val_loss: 1.4823 - val_accuracy: 0.6452 - lr: 1.0000e-05 - 16s/epoch - 98ms/step\n",
            "Epoch 58/60\n",
            "159/159 - 15s - loss: 0.1263 - accuracy: 0.9649 - val_loss: 1.5141 - val_accuracy: 0.6476 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "Epoch 59/60\n",
            "159/159 - 16s - loss: 0.1057 - accuracy: 0.9716 - val_loss: 1.5215 - val_accuracy: 0.6452 - lr: 1.0000e-05 - 16s/epoch - 98ms/step\n",
            "Epoch 60/60\n",
            "159/159 - 15s - loss: 0.1158 - accuracy: 0.9661 - val_loss: 1.5461 - val_accuracy: 0.6357 - lr: 1.0000e-05 - 15s/epoch - 97ms/step\n",
            "27/27 [==============================] - 3s 97ms/step - loss: 1.8600 - accuracy: 0.6037\n",
            "Scores:  {'loss': 1.8599634170532227, 'accuracy': 0.6037296056747437}\n",
            "27/27 [==============================] - 1s 23ms/step\n",
            "{'Basalt': {'precision': 0.5384615384615384, 'recall': 0.6, 'f1-score': 0.5675675675675675, 'support': 35}, 'Coal': {'precision': 0.8450704225352113, 'recall': 0.9375, 'f1-score': 0.8888888888888888, 'support': 64}, 'Granite': {'precision': 0.3220338983050847, 'recall': 0.475, 'f1-score': 0.3838383838383838, 'support': 40}, 'Limestone': {'precision': 0.582089552238806, 'recall': 0.5342465753424658, 'f1-score': 0.5571428571428572, 'support': 73}, 'Marble': {'precision': 0.7380952380952381, 'recall': 0.4305555555555556, 'f1-score': 0.543859649122807, 'support': 72}, 'Quartzite': {'precision': 0.875, 'recall': 0.42168674698795183, 'f1-score': 0.5691056910569107, 'support': 83}, 'Sandstone': {'precision': 0.4864864864864865, 'recall': 0.8709677419354839, 'f1-score': 0.6242774566473989, 'support': 62}, 'accuracy': 0.6037296037296037, 'macro avg': {'precision': 0.6267481623031951, 'recall': 0.6099938028316367, 'f1-score': 0.5906686420378306, 'support': 429}, 'weighted avg': {'precision': 0.6625514532379089, 'recall': 0.6037296037296037, 'f1-score': 0.6011132566093754, 'support': 429}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Test Accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇███████████▅▆▇▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▇▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▄▃▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▃▅▅▆▆▆▇▇▇▇▇████▇▇▇████▇▇████▅▅▅▄▄▄▄▅▄▅▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ▅▄▂▂▁▁▂▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▅▅▅▆▆▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            GFLOPs 3.86455\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Test Accuracy 0.60373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          accuracy 0.96607\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        best_epoch 22\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: best_val_accuracy 0.72857\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             epoch 59\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              loss 0.11577\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_accuracy 0.63571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          val_loss 1.5461\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/Whats-this-rock/wandb/offline-run-20220918_122334-2j72axzt\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20220918_122334-2j72axzt/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python src/models/train.py project=Whats-this-rockv3 \\\n",
        "                            wandb.mode=offline \\\n",
        "                            dataset_id=[1,2,3,4] \\\n",
        "                            sampling=oversampling \\\n",
        "                            epochs=50 \\\n",
        "                            lr=0.0005 \\\n",
        "                            optimizer=adamax \\\n",
        "                            backbone=resnet \\\n",
        "                            dropout_rate=0.3 \\\n",
        "                            trainable=False \\\n",
        "                            use_reduce_lr=True \\\n",
        "                            reduce_lr_factor=0.7 \\\n",
        "                            reduce_lr_patience=3 \\\n",
        "                            reduce_lr_min_lr=0.00005 \\\n",
        "                            earlystopping_patience=20 \\\n",
        "                            save_model=False \\\n",
        "                            # 'notes=\"No notes.\"' \\"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python src/evaluate.py"
      ],
      "metadata": {
        "id": "KIbRmgJ62ADB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Telegram Bot\n",
        "Uploading secrets with telegram key"
      ],
      "metadata": {
        "id": "TSbRchpaqiOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "telegram_token = getpass('Enter Telegram API Key: ')\n",
        "os.environ['TOKEN'] = telegram_token"
      ],
      "metadata": {
        "id": "ErKXBgT1qh52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install -r requirements.txt --quiet\n",
        "python src/bot.py"
      ],
      "metadata": {
        "id": "-VRJGfW_qlNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9mUak6P7bm"
      },
      "source": [
        "# Weights and Biases Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldXE23A3xKGP",
        "outputId": "5b786806-13d5-41df-fbeb-4fd3083abf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/udaylunawat/Whats-this-rock\n",
            "   1c1e59a..c6beb4d  hydra      -> origin/hydra\n",
            "Updating 1c1e59a..c6beb4d\n",
            "Fast-forward\n",
            " configs/sweep.yaml | 7 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 6 insertions(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADsiqB08Mthg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dd02e5-c405-47b5-8956-9acd206a67cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Creating sweep from: configs/sweep.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Created sweep with ID: \u001b[33mqb1s1zx7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: View sweep at: \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/sweeps/qb1s1zx7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run sweep agent with: \u001b[33mwandb agent rock-classifiers/Whats-this-rockv3/qb1s1zx7\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!wandb sweep \\\n",
        "    --project Whats-this-rockv3 \\\n",
        "    --entity rock-classifiers \\\n",
        "    configs/sweep.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcHI98wnM5H4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87bb4d30-2d10-4dcc-b647-935389d13780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2022-09-17 00:00:36,552 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2022-09-17 00:00:36,700 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2022-09-17 00:00:36,700 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\taugmentation: True\n",
            "\tbackbone: mobilenetv2\n",
            "\tbatch_size: 64\n",
            "\tclass_weights: True\n",
            "\tdata_path: data/4_tfds_dataset/\n",
            "\tdataset_id: [1]\n",
            "\tdropout_rate: 0.3\n",
            "\tearlystopping_patience: 20\n",
            "\tepochs: 100\n",
            "\timage_channels: 3\n",
            "\timage_size: 224\n",
            "\tloss: categorical_crossentropy\n",
            "\tlr: 1e-05\n",
            "\tmetrics: ['accuracy']\n",
            "\tmonitor: val_accuracy\n",
            "\tnotes: \n",
            "\tnum_classes: 7\n",
            "\toptimizer: adamax\n",
            "\tpreprocess: True\n",
            "\tproject: Whats-this-rockv3\n",
            "\treduce_lr_factor: 0.3\n",
            "\treduce_lr_min_lr: 1e-05\n",
            "\treduce_lr_patience: 7\n",
            "\tsampling: None\n",
            "\tsave_model: False\n",
            "\tseed: 42\n",
            "\ttrainable: True\n",
            "\tuse_earlystopping: True\n",
            "\tuse_pretrained_weights: True\n",
            "\tuse_reduce_lr: True\n",
            "\tuse_wandb: True\n",
            "\twand_mode: online\n",
            "2022-09-17 00:00:36,705 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python src/models/train.py augmentation=True backbone=mobilenetv2 batch_size=64 class_weights=True data_path=data/4_tfds_dataset/ dataset_id=[1] dropout_rate=0.3 earlystopping_patience=20 epochs=100 image_channels=3 image_size=224 loss=categorical_crossentropy lr=1e-05 metrics=['accuracy'] monitor=val_accuracy notes= num_classes=7 optimizer=adamax preprocess=True project=Whats-this-rockv3 reduce_lr_factor=0.3 reduce_lr_min_lr=1e-05 reduce_lr_patience=7 sampling=None save_model=False seed=42 trainable=True use_earlystopping=True use_pretrained_weights=True use_reduce_lr=True use_wandb=True wand_mode=online\n",
            "2022-09-17 00:00:41,718 - wandb.wandb_agent - INFO - Running runs: ['dye80h0i']\n",
            "notes: ''\n",
            "seed: 42\n",
            "lr: 1.0e-05\n",
            "epochs: 100\n",
            "augmentation: true\n",
            "class_weights: true\n",
            "optimizer: adamax\n",
            "loss: categorical_crossentropy\n",
            "metrics:\n",
            "- accuracy\n",
            "batch_size: 64\n",
            "num_classes: 7\n",
            "use_wandb: true\n",
            "project: Whats-this-rockv3\n",
            "wand_mode: online\n",
            "dataset_id:\n",
            "- 1\n",
            "data_path: data/4_tfds_dataset/\n",
            "sampling: None\n",
            "image_size: 224\n",
            "image_channels: 3\n",
            "backbone: mobilenetv2\n",
            "use_pretrained_weights: true\n",
            "trainable: true\n",
            "preprocess: true\n",
            "dropout_rate: 0.3\n",
            "save_model: false\n",
            "monitor: val_accuracy\n",
            "use_earlystopping: true\n",
            "earlystopping_patience: 20\n",
            "use_reduce_lr: true\n",
            "reduce_lr_factor: 0.3\n",
            "reduce_lr_min_lr: 1.0e-05\n",
            "reduce_lr_patience: 7\n",
            "\n",
            "data/4_tfds_dataset/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mudaylunawat\u001b[0m (\u001b[33mrock-classifiers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Whats-this-rock/wandb/run-20220917_000043-dye80h0i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/sweeps/qb1s1zx7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/runs/dye80h0i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./src)... Done. 0.1s\n",
            "\n",
            "Datasets used for Training:- [1]\n",
            "rock-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "renamed 'data/1_extracted/Dataset' -> 'data/1_extracted/dataset1'\n",
            "\n",
            "Processing dataset1\n",
            "Moving Granite: 100% 101/101 [00:00<00:00, 2876.97it/s]\n",
            "Moving Basalt: 100% 86/86 [00:00<00:00, 2046.80it/s]\n",
            "Moving Coal: 100% 369/369 [00:00<00:00, 5393.32it/s]\n",
            "Moving Limestone: 100% 338/338 [00:00<00:00, 4262.53it/s]\n",
            "Moving Sandstone: 100% 325/325 [00:00<00:00, 2211.81it/s]\n",
            "Moving Quartzite: 100% 477/477 [00:00<00:00, 8387.38it/s]\n",
            "Moving Marble: 100% 387/387 [00:00<00:00, 6430.92it/s]\n",
            "\n",
            "Files other than jpg and png.\n",
            "\n",
            "\n",
            "data/2_processed:\n",
            "Basalt\n",
            "Coal\n",
            "Granite\n",
            "Limestone\n",
            "Marble\n",
            "Quartzite\n",
            "Sandstone\n",
            "\n",
            "data/2_processed/Basalt:\n",
            "\n",
            "data/2_processed/Coal:\n",
            "Coal_111.jpeg\n",
            "Coal_127.jpeg\n",
            "Coal_133.jpeg\n",
            "Coal_162.jpeg\n",
            "Coal_183.jpeg\n",
            "Coal_202.jpeg\n",
            "Coal_205.jpeg\n",
            "Coal_228.jpeg\n",
            "Coal_235.jpeg\n",
            "Coal_252.jpeg\n",
            "Coal_265.jpeg\n",
            "Coal_288.jpeg\n",
            "Coal_320.jpeg\n",
            "Coal_35.jpeg\n",
            "Coal_363.jpeg\n",
            "Coal_366.jpeg\n",
            "Coal_45.jpeg\n",
            "Coal_68.jpeg\n",
            "Coal_77.jpeg\n",
            "Coal_82.jpeg\n",
            "Coal_93.jpeg\n",
            "\n",
            "data/2_processed/Granite:\n",
            "Granite_17.JPEG\n",
            "Granite_2.JPEG\n",
            "Granite_37.JPEG\n",
            "Granite_38.JPEG\n",
            "Granite_39.JPEG\n",
            "Granite_43.JPEG\n",
            "Granite_53.JPEG\n",
            "Granite_54.JPEG\n",
            "Granite_56.JPEG\n",
            "Granite_59.JPEG\n",
            "Granite_61.JPEG\n",
            "Granite_62.JPEG\n",
            "Granite_67.jpeg\n",
            "Granite_68.JPEG\n",
            "Granite_76.JPEG\n",
            "Granite_77.JPEG\n",
            "Granite_80.JPEG\n",
            "Granite_86.jpeg\n",
            "Granite_89.JPEG\n",
            "Granite_92.JPEG\n",
            "Granite_95.JPEG\n",
            "Granite_99.JPEG\n",
            "\n",
            "data/2_processed/Limestone:\n",
            "Limestone_109.jfif\n",
            "Limestone_122.jpeg\n",
            "Limestone_132.jpeg\n",
            "Limestone_151.jfif\n",
            "Limestone_311.jpeg\n",
            "Limestone_51.jfif\n",
            "Limestone_80.webp\n",
            "Limestone_84.jfif\n",
            "Limestone_94.webp\n",
            "Limestone_96.jpeg\n",
            "Limestone_97.jfif\n",
            "Limestone_98.jpeg\n",
            "\n",
            "data/2_processed/Marble:\n",
            "Marble_12.webp\n",
            "Marble_217.jfif\n",
            "Marble_279.webp\n",
            "Marble_89.jfif\n",
            "\n",
            "data/2_processed/Quartzite:\n",
            "Quartzite_318.webp\n",
            "\n",
            "data/2_processed/Sandstone:\n",
            "Sandstone_105.webp\n",
            "Sandstone_59.webp\n",
            "\n",
            "\n",
            "File types before cleaning:\n",
            "jpg     2004\n",
            "jpeg      28\n",
            "JPEG      20\n",
            "png       17\n",
            "webp       7\n",
            "jfif       7\n",
            "Name: file_name, dtype: int64\n",
            "\n",
            "\n",
            "Removing unsupported images...\n",
            "Total images before deletion = 2083\n",
            "Removed 15 unsupported files.\n",
            "\n",
            "\n",
            "Removing corrupted images...\n",
            "processing class directory  Coal\n",
            "file  data/2_processed/Coal/Coal_334.jpg  is not a valid image file\n",
            "processing class directory  Granite\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "processing class directory  Limestone\n",
            "processing class directory  Quartzite\n",
            "processing class directory  Marble\n",
            "processing class directory  Basalt\n",
            "processing class directory  Sandstone\n",
            "removed 44 bad images.\n",
            "\n",
            "Function 'remove_corrupted_images' executed in 13.9777s\n",
            "\n",
            "File types after cleaning:\n",
            "jpg     1982\n",
            "jpeg      25\n",
            "png       16\n",
            "JPEG       2\n",
            "Name: file_name, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2025 entries, 0 to 2024\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  2025 non-null   object\n",
            " 1   class      2025 non-null   object\n",
            " 2   file_path  2025 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 47.6+ KB\n",
            "\n",
            " None \n",
            "\n",
            "Quartzite    475\n",
            "Marble       383\n",
            "Coal         363\n",
            "Limestone    327\n",
            "Sandstone    322\n",
            "Granite       78\n",
            "Basalt        77\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Splitting files in Train, Validation and Test and saving to data/4_tfds_dataset/\n",
            "No Sampling.\n",
            "Copying files: 2025 files [00:00, 4046.97 files/s]\n",
            "\n",
            "\n",
            "\n",
            "Found 1617 files belonging to 7 classes.\n",
            "Found 199 files belonging to 7 classes.\n",
            "Found 209 files belonging to 7 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,849,031\n",
            "Trainable params: 3,814,919\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n",
            "\n",
            "Model loaded: mobilenetv2.\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "[2022-09-17 00:01:07,126][tensorflow][WARNING] - From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "Epoch 1/100\n",
            "26/26 [==============================] - 41s 487ms/step - loss: 2.2299 - accuracy: 0.1478 - val_loss: 2.0783 - val_accuracy: 0.1658 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 11s 412ms/step - loss: 2.0966 - accuracy: 0.1744 - val_loss: 2.0094 - val_accuracy: 0.1910 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 11s 412ms/step - loss: 2.0453 - accuracy: 0.1886 - val_loss: 1.9588 - val_accuracy: 0.2060 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.9927 - accuracy: 0.2121 - val_loss: 1.9189 - val_accuracy: 0.2111 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 11s 412ms/step - loss: 1.9488 - accuracy: 0.2239 - val_loss: 1.8835 - val_accuracy: 0.2261 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 11s 411ms/step - loss: 1.9191 - accuracy: 0.2338 - val_loss: 1.8537 - val_accuracy: 0.2211 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.8840 - accuracy: 0.2536 - val_loss: 1.8295 - val_accuracy: 0.2462 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.8530 - accuracy: 0.2696 - val_loss: 1.8054 - val_accuracy: 0.2663 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.8396 - accuracy: 0.2789 - val_loss: 1.7831 - val_accuracy: 0.2864 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.8222 - accuracy: 0.2944 - val_loss: 1.7621 - val_accuracy: 0.3015 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.7790 - accuracy: 0.2913 - val_loss: 1.7402 - val_accuracy: 0.3065 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.7723 - accuracy: 0.3086 - val_loss: 1.7197 - val_accuracy: 0.3166 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.7516 - accuracy: 0.3179 - val_loss: 1.7001 - val_accuracy: 0.3317 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 1.7386 - accuracy: 0.3173 - val_loss: 1.6816 - val_accuracy: 0.3668 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.6869 - accuracy: 0.3655 - val_loss: 1.6623 - val_accuracy: 0.3920 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.6872 - accuracy: 0.3537 - val_loss: 1.6422 - val_accuracy: 0.4221 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.6476 - accuracy: 0.3797 - val_loss: 1.6227 - val_accuracy: 0.4322 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.6486 - accuracy: 0.3692 - val_loss: 1.6028 - val_accuracy: 0.4724 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 1.6356 - accuracy: 0.3847 - val_loss: 1.5844 - val_accuracy: 0.4774 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.6143 - accuracy: 0.3958 - val_loss: 1.5633 - val_accuracy: 0.5075 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 1.5817 - accuracy: 0.4007 - val_loss: 1.5431 - val_accuracy: 0.5427 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 11s 432ms/step - loss: 1.5640 - accuracy: 0.4137 - val_loss: 1.5236 - val_accuracy: 0.5829 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.5678 - accuracy: 0.4181 - val_loss: 1.5055 - val_accuracy: 0.5779 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.4994 - accuracy: 0.4477 - val_loss: 1.4861 - val_accuracy: 0.5879 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.5147 - accuracy: 0.4428 - val_loss: 1.4666 - val_accuracy: 0.5879 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.4821 - accuracy: 0.4576 - val_loss: 1.4477 - val_accuracy: 0.5879 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.4621 - accuracy: 0.4725 - val_loss: 1.4276 - val_accuracy: 0.6080 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.4569 - accuracy: 0.4657 - val_loss: 1.4086 - val_accuracy: 0.6131 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.4409 - accuracy: 0.4663 - val_loss: 1.3900 - val_accuracy: 0.6281 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.4016 - accuracy: 0.5077 - val_loss: 1.3734 - val_accuracy: 0.6231 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.4144 - accuracy: 0.4923 - val_loss: 1.3572 - val_accuracy: 0.6382 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.3456 - accuracy: 0.5201 - val_loss: 1.3430 - val_accuracy: 0.6382 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 11s 420ms/step - loss: 1.3586 - accuracy: 0.5096 - val_loss: 1.3260 - val_accuracy: 0.6432 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.3362 - accuracy: 0.5306 - val_loss: 1.3107 - val_accuracy: 0.6432 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.3197 - accuracy: 0.5405 - val_loss: 1.2953 - val_accuracy: 0.6633 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 11s 431ms/step - loss: 1.2833 - accuracy: 0.5516 - val_loss: 1.2798 - val_accuracy: 0.6633 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.2770 - accuracy: 0.5430 - val_loss: 1.2654 - val_accuracy: 0.6583 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.2518 - accuracy: 0.5720 - val_loss: 1.2528 - val_accuracy: 0.6633 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.2215 - accuracy: 0.5813 - val_loss: 1.2385 - val_accuracy: 0.6583 - lr: 1.0000e-05\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.2184 - accuracy: 0.5770 - val_loss: 1.2244 - val_accuracy: 0.6683 - lr: 1.0000e-05\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.2175 - accuracy: 0.5578 - val_loss: 1.2114 - val_accuracy: 0.6683 - lr: 1.0000e-05\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.1891 - accuracy: 0.5850 - val_loss: 1.1981 - val_accuracy: 0.6734 - lr: 1.0000e-05\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 1.1548 - accuracy: 0.6098 - val_loss: 1.1848 - val_accuracy: 0.6734 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 1.1752 - accuracy: 0.6024 - val_loss: 1.1727 - val_accuracy: 0.6784 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.1338 - accuracy: 0.6172 - val_loss: 1.1607 - val_accuracy: 0.6884 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.1007 - accuracy: 0.6333 - val_loss: 1.1501 - val_accuracy: 0.6784 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.1047 - accuracy: 0.6351 - val_loss: 1.1363 - val_accuracy: 0.6985 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 1.0857 - accuracy: 0.6333 - val_loss: 1.1258 - val_accuracy: 0.7136 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.0558 - accuracy: 0.6339 - val_loss: 1.1165 - val_accuracy: 0.7136 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.0678 - accuracy: 0.6197 - val_loss: 1.1056 - val_accuracy: 0.7085 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.0549 - accuracy: 0.6456 - val_loss: 1.0962 - val_accuracy: 0.6985 - lr: 1.0000e-05\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.0513 - accuracy: 0.6438 - val_loss: 1.0867 - val_accuracy: 0.7035 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 11s 414ms/step - loss: 1.0514 - accuracy: 0.6537 - val_loss: 1.0784 - val_accuracy: 0.7035 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 1.0303 - accuracy: 0.6518 - val_loss: 1.0709 - val_accuracy: 0.7136 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 1.0119 - accuracy: 0.6506 - val_loss: 1.0608 - val_accuracy: 0.7186 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.9931 - accuracy: 0.6648 - val_loss: 1.0528 - val_accuracy: 0.7236 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 11s 421ms/step - loss: 0.9584 - accuracy: 0.6889 - val_loss: 1.0440 - val_accuracy: 0.7286 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.9525 - accuracy: 0.6790 - val_loss: 1.0340 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 0.9358 - accuracy: 0.6883 - val_loss: 1.0272 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 0.8977 - accuracy: 0.7112 - val_loss: 1.0211 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 0.9214 - accuracy: 0.6988 - val_loss: 1.0116 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 0.9173 - accuracy: 0.6908 - val_loss: 1.0046 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 0.8484 - accuracy: 0.7316 - val_loss: 0.9991 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 0.8536 - accuracy: 0.7236 - val_loss: 0.9909 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 11s 415ms/step - loss: 0.8375 - accuracy: 0.7236 - val_loss: 0.9856 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 0.8515 - accuracy: 0.7211 - val_loss: 0.9793 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.8182 - accuracy: 0.7267 - val_loss: 0.9734 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 0.8115 - accuracy: 0.7279 - val_loss: 0.9687 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 0.8082 - accuracy: 0.7248 - val_loss: 0.9637 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.7947 - accuracy: 0.7335 - val_loss: 0.9591 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 11s 419ms/step - loss: 0.7886 - accuracy: 0.7396 - val_loss: 0.9560 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.7637 - accuracy: 0.7396 - val_loss: 0.9505 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 11s 418ms/step - loss: 0.7446 - accuracy: 0.7563 - val_loss: 0.9452 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 11s 416ms/step - loss: 0.7644 - accuracy: 0.7551 - val_loss: 0.9399 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 11s 433ms/step - loss: 0.7262 - accuracy: 0.7532 - val_loss: 0.9374 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 11s 423ms/step - loss: 0.7190 - accuracy: 0.7675 - val_loss: 0.9336 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 11s 417ms/step - loss: 0.7226 - accuracy: 0.7650 - val_loss: 0.9324 - val_accuracy: 0.7337 - lr: 1.0000e-05\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.7187 - accuracy: 0.7619Restoring model weights from the end of the best epoch: 58.\n",
            "26/26 [==============================] - 11s 423ms/step - loss: 0.7187 - accuracy: 0.7619 - val_loss: 0.9291 - val_accuracy: 0.7387 - lr: 1.0000e-05\n",
            "Epoch 78: early stopping\n",
            "4/4 [==============================] - 1s 221ms/step - loss: 1.0064 - accuracy: 0.6459\n",
            "Scores:  {'loss': 1.0064247846603394, 'accuracy': 0.6459330320358276}\n",
            "4/4 [==============================] - 1s 42ms/step\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "{'Basalt': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'Coal': {'precision': 0.8048780487804879, 'recall': 0.8918918918918919, 'f1-score': 0.8461538461538461, 'support': 37}, 'Granite': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 9}, 'Limestone': {'precision': 0.5531914893617021, 'recall': 0.7647058823529411, 'f1-score': 0.6419753086419752, 'support': 34}, 'Marble': {'precision': 0.5666666666666667, 'recall': 0.4358974358974359, 'f1-score': 0.4927536231884058, 'support': 39}, 'Quartzite': {'precision': 0.6382978723404256, 'recall': 0.625, 'f1-score': 0.631578947368421, 'support': 48}, 'Sandstone': {'precision': 0.6590909090909091, 'recall': 0.8787878787878788, 'f1-score': 0.7532467532467532, 'support': 33}, 'accuracy': 0.645933014354067, 'macro avg': {'precision': 0.4603035694628845, 'recall': 0.5137547269900211, 'f1-score': 0.4808154969427716, 'support': 209}, 'weighted avg': {'precision': 0.588886585241705, 'recall': 0.645933014354067, 'f1-score': 0.6101683083095424, 'support': 209}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B sync reduced upload amount by 10.8%             \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Test Accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy ▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          loss █▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy ▁▁▂▂▂▃▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss ██▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            GFLOPs 0.30112\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Test Accuracy 0.64593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          accuracy 0.7619\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        best_epoch 57\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: best_val_accuracy 0.73869\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             epoch 77\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              loss 0.7187\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_accuracy 0.73869\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          val_loss 0.92906\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbumbling-sweep-1\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/runs/dye80h0i\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 3 media file(s), 25 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220917_000043-dye80h0i/logs\u001b[0m\n",
            "2022-09-17 00:24:49,105 - wandb.wandb_agent - INFO - Cleaning up finished run: dye80h0i\n",
            "2022-09-17 00:24:49,673 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2022-09-17 00:24:49,673 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\taugmentation: True\n",
            "\tbackbone: efficientnetv2m\n",
            "\tbatch_size: 64\n",
            "\tclass_weights: True\n",
            "\tdata_path: data/4_tfds_dataset/\n",
            "\tdataset_id: [1, 2, 3]\n",
            "\tdropout_rate: 0.3\n",
            "\tearlystopping_patience: 20\n",
            "\tepochs: 100\n",
            "\timage_channels: 3\n",
            "\timage_size: 224\n",
            "\tloss: categorical_crossentropy\n",
            "\tlr: 1e-05\n",
            "\tmetrics: ['accuracy']\n",
            "\tmonitor: val_accuracy\n",
            "\tnotes: \n",
            "\tnum_classes: 7\n",
            "\toptimizer: adam\n",
            "\tpreprocess: True\n",
            "\tproject: Whats-this-rockv3\n",
            "\treduce_lr_factor: 0.9\n",
            "\treduce_lr_min_lr: 1e-05\n",
            "\treduce_lr_patience: 1\n",
            "\tsampling: undersampling\n",
            "\tsave_model: False\n",
            "\tseed: 42\n",
            "\ttrainable: True\n",
            "\tuse_earlystopping: True\n",
            "\tuse_pretrained_weights: True\n",
            "\tuse_reduce_lr: True\n",
            "\tuse_wandb: True\n",
            "\twand_mode: online\n",
            "2022-09-17 00:24:49,678 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python src/models/train.py augmentation=True backbone=efficientnetv2m batch_size=64 class_weights=True data_path=data/4_tfds_dataset/ \"dataset_id=[1, 2, 3]\" dropout_rate=0.3 earlystopping_patience=20 epochs=100 image_channels=3 image_size=224 loss=categorical_crossentropy lr=1e-05 metrics=['accuracy'] monitor=val_accuracy notes= num_classes=7 optimizer=adam preprocess=True project=Whats-this-rockv3 reduce_lr_factor=0.9 reduce_lr_min_lr=1e-05 reduce_lr_patience=1 sampling=undersampling save_model=False seed=42 trainable=True use_earlystopping=True use_pretrained_weights=True use_reduce_lr=True use_wandb=True wand_mode=online\n",
            "2022-09-17 00:24:54,690 - wandb.wandb_agent - INFO - Running runs: ['ho2hni0x']\n",
            "notes: ''\n",
            "seed: 42\n",
            "lr: 1.0e-05\n",
            "epochs: 100\n",
            "augmentation: true\n",
            "class_weights: true\n",
            "optimizer: adam\n",
            "loss: categorical_crossentropy\n",
            "metrics:\n",
            "- accuracy\n",
            "batch_size: 64\n",
            "num_classes: 7\n",
            "use_wandb: true\n",
            "project: Whats-this-rockv3\n",
            "wand_mode: online\n",
            "dataset_id:\n",
            "- 1\n",
            "- 2\n",
            "- 3\n",
            "data_path: data/4_tfds_dataset/\n",
            "sampling: undersampling\n",
            "image_size: 224\n",
            "image_channels: 3\n",
            "backbone: efficientnetv2m\n",
            "use_pretrained_weights: true\n",
            "trainable: true\n",
            "preprocess: true\n",
            "dropout_rate: 0.3\n",
            "save_model: false\n",
            "monitor: val_accuracy\n",
            "use_earlystopping: true\n",
            "earlystopping_patience: 20\n",
            "use_reduce_lr: true\n",
            "reduce_lr_factor: 0.9\n",
            "reduce_lr_min_lr: 1.0e-05\n",
            "reduce_lr_patience: 1\n",
            "\n",
            "data/4_tfds_dataset/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mudaylunawat\u001b[0m (\u001b[33mrock-classifiers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Whats-this-rock/wandb/run-20220917_002502-ho2hni0x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-sweep-19\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/sweeps/qb1s1zx7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/rock-classifiers/Whats-this-rockv3/runs/ho2hni0x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./src)... Done. 0.1s\n",
            "\n",
            "Datasets used for Training:- [1, 2, 3]\n",
            "rock-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "renamed 'data/1_extracted/Dataset' -> 'data/1_extracted/dataset1'\n",
            "igneous-metamorphic-sedimentary-rocks-and-minerals.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "\n",
            "Processing dataset3\n",
            "Moving Granite: 100% 45/45 [00:00<00:00, 6136.01it/s]\n",
            "Moving Limestone: 100% 57/57 [00:00<00:00, 11748.75it/s]\n",
            "Moving Quartzite: 100% 64/64 [00:00<00:00, 11466.21it/s]\n",
            "Moving Marble: 100% 70/70 [00:00<00:00, 11536.40it/s]\n",
            "Moving Basalt: 100% 39/39 [00:00<00:00, 10859.58it/s]\n",
            "Moving Sandstone: 100% 47/47 [00:00<00:00, 11282.75it/s]\n",
            "Moving Granite: 100% 20/20 [00:00<00:00, 9491.52it/s]\n",
            "Moving Limestone: 100% 23/23 [00:00<00:00, 9885.13it/s]\n",
            "Moving Quartzite: 100% 17/17 [00:00<00:00, 9754.20it/s]\n",
            "Moving Marble: 100% 19/19 [00:00<00:00, 9127.45it/s]\n",
            "Moving Basalt: 100% 13/13 [00:00<00:00, 9176.36it/s]\n",
            "Moving Sandstone: 100% 19/19 [00:00<00:00, 10113.17it/s]\n",
            "\n",
            "Processing dataset1\n",
            "Moving Granite: 100% 101/101 [00:00<00:00, 3252.70it/s]\n",
            "Moving Basalt: 100% 86/86 [00:00<00:00, 1695.85it/s]\n",
            "Moving Coal: 100% 369/369 [00:00<00:00, 4325.31it/s]\n",
            "Moving Limestone: 100% 338/338 [00:00<00:00, 3563.87it/s]\n",
            "Moving Sandstone: 100% 325/325 [00:00<00:00, 3634.10it/s]\n",
            "Moving Quartzite: 100% 477/477 [00:00<00:00, 8865.13it/s]\n",
            "Moving Marble: 100% 387/387 [00:00<00:00, 6742.97it/s]\n",
            "\n",
            "Processing dataset2\n",
            "Moving granite: 100% 113/113 [00:00<00:00, 9801.60it/s]\n",
            "Moving Basalt: 100% 94/94 [00:00<00:00, 10457.11it/s]\n",
            "Moving quartzite: 100% 40/40 [00:00<00:00, 11170.66it/s]\n",
            "Moving marble: 100% 40/40 [00:00<00:00, 11391.37it/s]\n",
            "Moving Limestone: 100% 114/114 [00:00<00:00, 10802.25it/s]\n",
            "Moving coal: 100% 100/100 [00:00<00:00, 11114.57it/s]\n",
            "Moving Sandstone: 100% 45/45 [00:00<00:00, 9441.90it/s]\n",
            "\n",
            "Files other than jpg and png.\n",
            "\n",
            "\n",
            "data/2_processed:\n",
            "Basalt\n",
            "Coal\n",
            "Granite\n",
            "Limestone\n",
            "Marble\n",
            "Quartzite\n",
            "Sandstone\n",
            "\n",
            "data/2_processed/Basalt:\n",
            "\n",
            "data/2_processed/Coal:\n",
            "Coal_111.jpeg\n",
            "Coal_127.jpeg\n",
            "Coal_133.jpeg\n",
            "Coal_162.jpeg\n",
            "Coal_183.jpeg\n",
            "Coal_202.jpeg\n",
            "Coal_205.jpeg\n",
            "Coal_228.jpeg\n",
            "Coal_235.jpeg\n",
            "Coal_252.jpeg\n",
            "Coal_265.jpeg\n",
            "Coal_288.jpeg\n",
            "Coal_320.jpeg\n",
            "Coal_35.jpeg\n",
            "Coal_363.jpeg\n",
            "Coal_366.jpeg\n",
            "Coal_45.jpeg\n",
            "Coal_68.jpeg\n",
            "Coal_77.jpeg\n",
            "Coal_82.jpeg\n",
            "Coal_93.jpeg\n",
            "\n",
            "data/2_processed/Granite:\n",
            "Granite_102.JPEG\n",
            "Granite_103.JPEG\n",
            "Granite_104.JPEG\n",
            "Granite_108.JPEG\n",
            "Granite_118.JPEG\n",
            "Granite_119.JPEG\n",
            "Granite_121.JPEG\n",
            "Granite_124.JPEG\n",
            "Granite_126.JPEG\n",
            "Granite_127.JPEG\n",
            "Granite_132.jpeg\n",
            "Granite_133.JPEG\n",
            "Granite_141.JPEG\n",
            "Granite_142.JPEG\n",
            "Granite_145.JPEG\n",
            "Granite_151.jpeg\n",
            "Granite_154.JPEG\n",
            "Granite_157.JPEG\n",
            "Granite_160.JPEG\n",
            "Granite_164.JPEG\n",
            "Granite_67.JPEG\n",
            "Granite_82.JPEG\n",
            "\n",
            "data/2_processed/Limestone:\n",
            "Limestone_131.jfif\n",
            "Limestone_160.webp\n",
            "Limestone_164.jfif\n",
            "Limestone_174.webp\n",
            "Limestone_176.jpeg\n",
            "Limestone_177.jfif\n",
            "Limestone_178.jpeg\n",
            "Limestone_189.jfif\n",
            "Limestone_202.jpeg\n",
            "Limestone_212.jpeg\n",
            "Limestone_231.jfif\n",
            "Limestone_391.jpeg\n",
            "\n",
            "data/2_processed/Marble:\n",
            "Marble_101.webp\n",
            "Marble_178.jfif\n",
            "Marble_306.jfif\n",
            "Marble_368.webp\n",
            "\n",
            "data/2_processed/Quartzite:\n",
            "Quartzite_399.webp\n",
            "\n",
            "data/2_processed/Sandstone:\n",
            "Sandstone_125.webp\n",
            "Sandstone_171.webp\n",
            "\n",
            "\n",
            "File types before cleaning:\n",
            "jpg     2983\n",
            "jpeg      28\n",
            "JPEG      20\n",
            "png       17\n",
            "webp       7\n",
            "jfif       7\n",
            "Name: file_name, dtype: int64\n",
            "\n",
            "\n",
            "Removing unsupported images...\n",
            "Total images before deletion = 3062\n",
            "Removed 15 unsupported files.\n",
            "\n",
            "\n",
            "Removing corrupted images...\n",
            "processing class directory  Coal\n",
            "file  data/2_processed/Coal/Coal_391.jpg  is not a valid image file\n",
            "file  data/2_processed/Coal/Coal_334.jpg  is not a valid image file\n",
            "processing class directory  Granite\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "libpng warning: iCCP: known incorrect sRGB profile\n",
            "processing class directory  Limestone\n",
            "processing class directory  Quartzite\n",
            "processing class directory  Marble\n",
            "processing class directory  Basalt\n",
            "processing class directory  Sandstone\n",
            "removed 46 bad images.\n",
            "\n",
            "Function 'remove_corrupted_images' executed in 13.3264s\n",
            "\n",
            "File types after cleaning:\n",
            "jpg     2959\n",
            "jpeg      25\n",
            "png       16\n",
            "JPEG       2\n",
            "Name: file_name, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3002 entries, 0 to 3001\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   file_name  3002 non-null   object\n",
            " 1   class      3002 non-null   object\n",
            " 2   file_path  3002 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 70.5+ KB\n",
            "\n",
            " None \n",
            "\n",
            "Quartzite    596\n",
            "Limestone    521\n",
            "Marble       512\n",
            "Coal         461\n",
            "Sandstone    433\n",
            "Granite      256\n",
            "Basalt       223\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Splitting files in Train, Validation and Test and saving to data/4_tfds_dataset/\n",
            "No Sampling.\n",
            "Copying files: 3002 files [00:00, 4860.35 files/s]\n",
            "\n",
            "\n",
            "\n",
            "Found 2397 files belonging to 7 classes.\n",
            "Found 298 files belonging to 7 classes.\n",
            "Found 307 files belonging to 7 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetv2-m (Functiona  (None, 7, 7, 1280)       53150388  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,741,435\n",
            "Trainable params: 54,449,403\n",
            "Non-trainable params: 292,032\n",
            "_________________________________________________________________\n",
            "\n",
            "Model loaded: efficientnetv2m.\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "[2022-09-17 00:25:47,820][tensorflow][WARNING] - From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 113s 1s/step - loss: 1.9636 - accuracy: 0.1598 - val_loss: 1.9292 - val_accuracy: 0.1745 - lr: 1.0000e-05\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 35s 903ms/step - loss: 1.9023 - accuracy: 0.2232 - val_loss: 1.9109 - val_accuracy: 0.2550 - lr: 1.0000e-05\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 35s 916ms/step - loss: 1.8494 - accuracy: 0.2720 - val_loss: 1.8837 - val_accuracy: 0.3289 - lr: 1.0000e-05\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.7973 - accuracy: 0.3267 - val_loss: 1.8548 - val_accuracy: 0.3624 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.7275 - accuracy: 0.3742 - val_loss: 1.8175 - val_accuracy: 0.3826 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 35s 919ms/step - loss: 1.6382 - accuracy: 0.4297 - val_loss: 1.7654 - val_accuracy: 0.4094 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.5469 - accuracy: 0.5010 - val_loss: 1.7127 - val_accuracy: 0.4430 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.4490 - accuracy: 0.5440 - val_loss: 1.6691 - val_accuracy: 0.4530 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 35s 907ms/step - loss: 1.3533 - accuracy: 0.5853 - val_loss: 1.6104 - val_accuracy: 0.4530 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.2359 - accuracy: 0.6275 - val_loss: 1.5583 - val_accuracy: 0.4933 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 35s 907ms/step - loss: 1.1244 - accuracy: 0.6746 - val_loss: 1.5080 - val_accuracy: 0.4799 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 1.0118 - accuracy: 0.7196 - val_loss: 1.4636 - val_accuracy: 0.5168 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 35s 922ms/step - loss: 0.9253 - accuracy: 0.7409 - val_loss: 1.4291 - val_accuracy: 0.5235 - lr: 1.0000e-05\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 35s 924ms/step - loss: 0.8365 - accuracy: 0.7635 - val_loss: 1.4018 - val_accuracy: 0.5369 - lr: 1.0000e-05\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 35s 923ms/step - loss: 0.7485 - accuracy: 0.8039 - val_loss: 1.3493 - val_accuracy: 0.5470 - lr: 1.0000e-05\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 35s 918ms/step - loss: 0.6739 - accuracy: 0.8281 - val_loss: 1.3245 - val_accuracy: 0.5705 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 35s 909ms/step - loss: 0.5936 - accuracy: 0.8494 - val_loss: 1.3096 - val_accuracy: 0.5705 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 35s 932ms/step - loss: 0.5306 - accuracy: 0.8719 - val_loss: 1.2832 - val_accuracy: 0.5973 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 34s 906ms/step - loss: 0.4563 - accuracy: 0.8911 - val_loss: 1.3022 - val_accuracy: 0.5738 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 35s 907ms/step - loss: 0.4050 - accuracy: 0.9028 - val_loss: 1.2610 - val_accuracy: 0.5839 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 35s 917ms/step - loss: 0.3560 - accuracy: 0.9216 - val_loss: 1.2933 - val_accuracy: 0.6040 - lr: 1.0000e-05\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 35s 907ms/step - loss: 0.3036 - accuracy: 0.9370 - val_loss: 1.2890 - val_accuracy: 0.5940 - lr: 1.0000e-05\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 35s 919ms/step - loss: 0.2641 - accuracy: 0.9520 - val_loss: 1.2785 - val_accuracy: 0.6309 - lr: 1.0000e-05\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 34s 906ms/step - loss: 0.2257 - accuracy: 0.9620 - val_loss: 1.3287 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 34s 905ms/step - loss: 0.1948 - accuracy: 0.9700 - val_loss: 1.3165 - val_accuracy: 0.6007 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 34s 905ms/step - loss: 0.1599 - accuracy: 0.9796 - val_loss: 1.3337 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 34s 905ms/step - loss: 0.1339 - accuracy: 0.9858 - val_loss: 1.3214 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 34s 901ms/step - loss: 0.1132 - accuracy: 0.9862 - val_loss: 1.3960 - val_accuracy: 0.6107 - lr: 1.0000e-05\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 35s 910ms/step - loss: 0.0979 - accuracy: 0.9904 - val_loss: 1.3846 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0818 - accuracy: 0.9933 - val_loss: 1.4103 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0705 - accuracy: 0.9946 - val_loss: 1.4841 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 35s 921ms/step - loss: 0.0602 - accuracy: 0.9958 - val_loss: 1.4580 - val_accuracy: 0.6376 - lr: 1.0000e-05\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0529 - accuracy: 0.9967 - val_loss: 1.4720 - val_accuracy: 0.6342 - lr: 1.0000e-05\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 34s 905ms/step - loss: 0.0476 - accuracy: 0.9975 - val_loss: 1.5309 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0392 - accuracy: 0.9979 - val_loss: 1.5181 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0331 - accuracy: 0.9975 - val_loss: 1.5926 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 34s 906ms/step - loss: 0.0303 - accuracy: 0.9996 - val_loss: 1.5820 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0300 - accuracy: 0.9983 - val_loss: 1.6263 - val_accuracy: 0.6174 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 35s 908ms/step - loss: 0.0241 - accuracy: 0.9979 - val_loss: 1.6226 - val_accuracy: 0.6174 - lr: 1.0000e-05\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0239 - accuracy: 0.9979 - val_loss: 1.6569 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 34s 901ms/step - loss: 0.0211 - accuracy: 0.9996 - val_loss: 1.6703 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0208 - accuracy: 0.9983 - val_loss: 1.7115 - val_accuracy: 0.6107 - lr: 1.0000e-05\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.7374 - val_accuracy: 0.6074 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 35s 916ms/step - loss: 0.0158 - accuracy: 0.9987 - val_loss: 1.6511 - val_accuracy: 0.6477 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 35s 908ms/step - loss: 0.0181 - accuracy: 0.9987 - val_loss: 1.8897 - val_accuracy: 0.5805 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.9540 - val_accuracy: 0.5839 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0135 - accuracy: 0.9996 - val_loss: 1.8754 - val_accuracy: 0.6007 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 34s 901ms/step - loss: 0.0110 - accuracy: 0.9996 - val_loss: 1.9023 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 34s 906ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.0048 - val_accuracy: 0.5940 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0117 - accuracy: 0.9987 - val_loss: 1.8896 - val_accuracy: 0.6107 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.6074 - lr: 1.0000e-05\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0101 - accuracy: 0.9996 - val_loss: 1.9825 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 34s 918ms/step - loss: 0.0093 - accuracy: 0.9996 - val_loss: 1.9685 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.9403 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 2.0078 - val_accuracy: 0.6242 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.0028 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0484 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 34s 901ms/step - loss: 0.0066 - accuracy: 0.9992 - val_loss: 2.0916 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 34s 903ms/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 2.1493 - val_accuracy: 0.6040 - lr: 1.0000e-05\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 34s 904ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 2.1039 - val_accuracy: 0.6040 - lr: 1.0000e-05\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 34s 905ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1208 - val_accuracy: 0.6309 - lr: 1.0000e-05\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 34s 902ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1656 - val_accuracy: 0.6275 - lr: 1.0000e-05\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 34s 900ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 2.1988 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 64/100\n",
            " 4/38 [==>...........................] - ETA: 29s - loss: 0.0041 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "!wandb agent rock-classifiers/Whats-this-rockv3/qb1s1zx7"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BrmYJMgw8oxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}