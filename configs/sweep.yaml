method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  notes:
    value: ""
  seed:
    values: [1]
  lr:
    distribution: uniform
    min: 5e-5
    max: 8e-3
  lr_decay_steps:
    values: [100, 500, 1000]
  lr_schedule:
    values:
      - cosine_decay
      - exponentialdecay
      - cosine_decay_restarts
  epochs:
    value: 50
  augmentation:
    value: True
  class_weights:
    value: True
  optimizer:
    values: [adam, adamax]
  loss:
    value: categorical_crossentropy
  metrics:
    value: ["accuracy"]
  batch_size:
    value: 64
  num_classes:
    value: 7
  train_split:
    values:
      - 0.80
  data_path:
    value: data/4_tfds_dataset/
  wandb.use:
    value: True
  wandb.mode:
    value: online
  wandb.project:
    value: Whats-this-rockv10
  dataset_id:
    values:
      - [1]
  image_size:
    value: 224
  image_channels:
    value: 3
  sampling:
    values: [None]
  backbone:
    values: [resnet]
  use_pretrained_weights:
    values: [True]
  trainable:
    values: [False]
  last_layers:
    values: [5, 10, 20, 30]
  custom_callback:
    values: [False, True]
  preprocess:
    value: True
  dropout_rate:
    values: [0.1, 0.3]
  monitor:
    values: ["val_loss", "val_f1_score", "val_accuracy"]
  earlystopping.use:
    values: [False]
  earlystopping.patience:
    values: [10]
  reduce_lr.use:
    values: [True]
  reduce_lr.factor:
    values: [.9, .5, .3]
  reduce_lr.patience:
    values: [1, 5, 10]
  reduce_lr.min_lr:
    values: [5e-4, 1e-4, 1e-5, 5e-6]
  save_model:
    value: False

program: src/models/train.py
command:
  - ${env}
  - python
  - ${program}
  - ${args_no_hyphens}
