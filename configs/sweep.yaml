method: bayes
metric:
  goal: maximize
  name: val_f1_score
parameters:
  notes:
    value: ""
  seed:
    value: 42
  lr:
    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]
  epochs:
    value: 30
  augmentation:
    value: True
  class_weights:
    value: True
  optimizer:
    value: adam
  loss:
    value: categorical_crossentropy
  metrics:
    value: ["accuracy"]
  batch_size:
    value: 64
  num_classes:
    value: 7
  paths:
    - data:
        value: ${hydra:runtime.cwd}/data/4_tfds_dataset/

wandb:
  - use:
      value: True
    project:
      value: Whats-this-rock

dataset:
  - id:
      value: [1, 2, 3, 4]
    dir:
      value: data/3_consume/
    image:
      size:
        value: 124
      channels:
        value: 3
    classes:
      value: 10
    sampling:
      value: None

model:
  - backbone:
      value: efficientnetv2m
    use_pretrained_weights:
      value: True
    trainable:
      value: True
    preprocess:
      value: True
    dropout_rate:
      value: 0.3

callback:
  - monitor:
      value: "val_f1_score"
    earlystopping:
      patience:
        value: 10
    reduce_lr:
      factor:
        values: [.9, .7, .5]
      min_lr: 0.00001
      patience:
        values: [1, 2, 3, 4]
    save_model:
      status:
        value: True
      best_only:
        value: True

program: src/models/train.py
